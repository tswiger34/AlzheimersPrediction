{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AwVgzqCBVI8k"
      ],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPw3QxbYwP/lpOWdI7Z1bP6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tswiger34/AlzheimersPrediction/blob/main/ImageClassifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[Load Dependencies](#scrollTo=Mma4gQLDIfCq)\n",
        "\n",
        ">[Image Loading and Preprocessing](#scrollTo=AwVgzqCBVI8k)\n",
        "\n",
        ">[Model Training](#scrollTo=kQPo1bPZVPn7)\n",
        "\n",
        ">>[Create and Load Models](#scrollTo=3Gim6jahVYYi)\n",
        "\n",
        ">>[Train Models](#scrollTo=W2Lm7kQZVbVL)\n",
        "\n",
        ">[Model Testing](#scrollTo=2UYtnVA3VTS9)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "CLl8U0o0Idfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dependencies"
      ],
      "metadata": {
        "id": "Mma4gQLDIfCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqnjsnRKVht7",
        "outputId": "3f057bf4-4dfb-4fcc-d010-9b5a91a6b8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning/Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import nibabel as nib\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torchvision import transforms, utils\n",
        "from torchvision.models import resnet18\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "# Load train/test info data frames\n",
        "train_info = pd.read_csv('/content/drive/MyDrive/PBHLT7120_Project/Data/TrainSets/Images/ImageTrainDataInfo.csv')\n",
        "train_ptids = train_info['Subject'].unique()\n",
        "img_metadata = pd.read_csv('/content/drive/MyDrive/PBHLT7120_Project/Data/FullData/CSVFiles/ImageMetadata.csv')\n",
        "img_train_df = img_metadata[img_metadata['Subject'].isin(train_ptids)]\n",
        "\n",
        "root_dir = \"/content/drive/MyDrive/PBHLT7120_Project/Data/FullData/Images/1.5T_Images\"\n",
        "folders = os.listdir(root_dir)\n",
        "new_df = pd.DataFrame(columns=['Subject', 'Folder_Num'])\n",
        "\n",
        "for folder in folders:\n",
        "   path = os.path.join(root_dir, folder)\n",
        "   new_df\n"
      ],
      "metadata": {
        "id": "W3ylja2kUzF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a list to store PTID/ImageID pairs\n",
        "data = []\n",
        "\n",
        "## Traverse Folders\n",
        "for folder in os.listdir(root_dir):\n",
        "    print(folder)\n",
        "    folder_path = os.path.join(root_dir, folder)\n",
        "    if os.path.isdir(folder_path) and folder.startswith('ADNI1_Complete'):\n",
        "        adni_path = os.path.join(folder_path, 'ADNI')\n",
        "        if os.path.isdir(adni_path):\n",
        "            for ptid in os.listdir(adni_path):\n",
        "                ptid_path = os.path.join(adni_path, ptid)\n",
        "                if os.path.isdir(ptid_path):\n",
        "                    # Collect ImageID information\n",
        "                    for image_name in os.listdir(ptid_path):\n",
        "                        if os.path.isdir(os.path.join(ptid_path, image_name)):\n",
        "                            for date_info in os.listdir(os.path.join(ptid_path, image_name)):\n",
        "                                date_path = os.path.join(ptid_path, image_name, date_info)\n",
        "                                if os.path.isdir(date_path):\n",
        "                                    for img_id in os.listdir(date_path):\n",
        "                                        img_path = os.path.join(date_path, img_id)\n",
        "                                        if os.path.isdir(img_path):\n",
        "                                          img_name = os.listdir(img_path)[0]\n",
        "                                          full_path = os.path.join(img_path, img_name)\n",
        "                                          data.append({'PatientID': ptid, 'ImageID': img_id, 'FolderName':folder, 'FullPath':full_path})\n",
        "\n",
        "# Save DataFrame to a CSV file\n",
        "df = pd.DataFrame(data)\n",
        "csv_path = os.path.join(root_dir, 'PTID_ImageIDs.csv')\n",
        "df.to_csv(csv_path, index=False)\n",
        "print(f\"DataFrame created with {len(df)} entries\")\n",
        "print(f\"CSV saved at: {csv_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2AHBnE1hR79",
        "outputId": "de2fdfbc-4f90-40d2-8cfc-8651d2283e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADNI1_Complete 3Yr 1.5T2\n",
            "ADNI1_Complete 3Yr 1.5T3\n",
            "ADNI1_Complete 3Yr 1.5T4\n",
            "ADNI1_Complete 3Yr 1.5T1\n",
            "ADNI1_Complete 3Yr 1.5T5\n",
            "ADNI1_Complete 3Yr 1.5T6\n",
            "ADNI1_Complete 3Yr 1.5T7\n",
            "ADNI1_Complete 3Yr 1.5T8\n",
            "ADNI1_Complete 3Yr 1.5T9\n",
            "Master\n",
            "ADNI1_Complete 3Yr 1.5T10\n",
            "ADNI1_Complete 3Yr 1.5T11\n",
            "PTID_ImageIDs.csv\n",
            "DataFrame created with 2170 entries\n",
            "CSV saved at: /content/drive/MyDrive/PBHLT7120_Project/Data/FullData/Images/1.5T_Images/PTID_ImageIDs.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ON5dBPMbG2jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/PBHLT7120_Project/Data/FullData/Images/1.5T_Images/PTID_ImageIDs.csv')\n",
        "print(len(df))\n",
        "print(df['FullPath'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNBZPtfLaNip",
        "outputId": "6394fae1-3290-4618-ce82-f8612b284bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2170\n",
            "0       /content/drive/MyDrive/PBHLT7120_Project/Data/...\n",
            "1       /content/drive/MyDrive/PBHLT7120_Project/Data/...\n",
            "2       /content/drive/MyDrive/PBHLT7120_Project/Data/...\n",
            "3       /content/drive/MyDrive/PBHLT7120_Project/Data/...\n",
            "4       /content/drive/MyDrive/PBHLT7120_Project/Data/...\n",
            "                              ...                        \n",
            "2165    /content/drive/MyDrive/PBHLT7120_Project/Data/...\n",
            "2166    /content/drive/MyDrive/PBHLT7120_Project/Data/...\n",
            "2167    /content/drive/MyDrive/PBHLT7120_Project/Data/...\n",
            "2168    /content/drive/MyDrive/PBHLT7120_Project/Data/...\n",
            "2169    /content/drive/MyDrive/PBHLT7120_Project/Data/...\n",
            "Name: FullPath, Length: 2170, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_metadata = pd.read_csv('/content/drive/MyDrive/PBHLT7120_Project/Data/FullData/CSVFiles/ImageMetadata.csv')\n",
        "full_df = pd.merge(df, img_metadata, left_on=('ImageID', 'PatientID'), right_on=('Image Data ID', 'Subject'), how='outer')\n",
        "full_df.to_csv('/content/drive/MyDrive/PBHLT7120_Project/Data/FullData/CSVFiles/PTID_ImageIDs.csv', index=False)"
      ],
      "metadata": {
        "id": "sQ1ZzXCNnT8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Final Image Train Data Frame\n",
        "train_ptids = train_info['Subject'].unique()\n",
        "img_ptids, lr_ptids = train_test_split(train_ptids, test_size=0.6, random_state=42)\n",
        "full_train = full_df[full_df['Subject'].isin(img_ptids)]\n",
        "full_train = full_train.loc[full_train['Visit'].isin(['sc', 'bl', 'm06', 'm12'])]\n",
        "full_train = pd.merge(full_train, train_info[['Subject','DIAGNOSIS_GROUP']], left_on=('Subject'), right_on=('Subject'), how='right')\n",
        "full_train = full_train.dropna(subset=['FolderName'])\n",
        "full_train.reset_index(drop=True, inplace=True)\n",
        "print(full_train.shape)\n",
        "\n",
        "## Final Test Data Frame\n",
        "test_info = pd.read_csv('/content/drive/MyDrive/PBHLT7120_Project/Data/TestSets/Images/ImageTestDataInfo.csv')\n",
        "test_ptids = test_info['Subject'].unique()\n",
        "full_test = full_df[full_df['Subject'].isin(test_ptids)]\n",
        "full_test = full_test.loc[full_test['Visit'].isin(['sc', 'bl', 'm06', 'm12'])]\n",
        "full_test = pd.merge(full_test, test_info[['Subject','DIAGNOSIS_GROUP']], left_on=('Subject'), right_on=('Subject'), how='left')\n",
        "full_test = full_test.dropna(subset=['FolderName'])\n",
        "full_test.reset_index(drop=True, inplace=True)\n",
        "print(full_test.shape)\n",
        "\n",
        "## LR Train Data Frame\n",
        "lr_traininfo = full_df[full_df['Subject'].isin(lr_ptids)]\n",
        "lr_traininfo = lr_traininfo.loc[lr_traininfo['Visit'].isin(['sc', 'bl', 'm06'])]\n",
        "lr_traininfo = pd.merge(lr_traininfo, train_info[['Subject','DIAGNOSIS_GROUP']], left_on=('Subject'), right_on=('Subject'), how='right')\n",
        "lr_traininfo = lr_traininfo.dropna(subset=['FolderName'])\n",
        "lr_traininfo.reset_index(drop=True, inplace=True)\n",
        "print(lr_traininfo.shape)\n",
        "\n",
        "lr_testinfo = full_df[full_df['Subject'].isin(test_ptids)]\n",
        "lr_testinfo = lr_testinfo.loc[lr_testinfo['Visit'].isin(['sc', 'bl', 'm06'])]\n",
        "lr_testinfo = pd.merge(lr_testinfo, test_info[['Subject','DIAGNOSIS_GROUP']], left_on=('Subject'), right_on=('Subject'), how='right')\n",
        "lr_testinfo = lr_testinfo.dropna(subset=['FolderName'])\n",
        "lr_testinfo.reset_index(drop=True, inplace=True)\n",
        "print(lr_testinfo.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ir9Td1G-crm-",
        "outputId": "568ed200-37cc-4506-90c9-d932dcdac441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(391, 17)\n",
            "(254, 17)\n",
            "(384, 17)\n",
            "(171, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Define Dataset Class\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, dataframe, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dataframe (pd.DataFrame): DataFrame containing 'PatientID', 'Description', 'ImageID', and 'Group'.\n",
        "            root_dir (str): Root directory of the dataset.\n",
        "            transform (callable, optional): Optional transform to be applied on an image.\n",
        "        \"\"\"\n",
        "        self.dataframe = dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if isinstance(idx, int):\n",
        "            row = self.dataframe.iloc[idx]\n",
        "        else:\n",
        "            row = self.dataframe.loc[idx]\n",
        "        # Construct image path\n",
        "        new_image_path = os.path.join(\n",
        "            self.root_dir,\n",
        "            f\"{row['FolderName']}\",\n",
        "            \"ADNI\",\n",
        "            row['Subject'],\n",
        "            row['Description'].replace(' ', '_').replace(';', '_')\n",
        "        )\n",
        "        if not os.path.exists(new_image_path):\n",
        "          raise FileNotFoundError(f\"Directory not found: {new_image_path}\")\n",
        "        if os.path.isdir(new_image_path):\n",
        "            date_folder = os.listdir(new_image_path)[0]\n",
        "            date_path = os.path.join(new_image_path, date_folder)\n",
        "            if os.path.isdir(date_path):\n",
        "              image_id = os.listdir(date_path)[0]\n",
        "              image_folder = os.path.join(date_path, image_id)\n",
        "              image_name = os.listdir(image_folder)[0]\n",
        "              image_path = os.path.join(image_folder, image_name)\n",
        "\n",
        "        # Load image\n",
        "        try:\n",
        "            image = nib.load(image_path).get_fdata()\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error loading image: {image_path}. Details: {e}\")\n",
        "        # Normalize to 0,1\n",
        "        image = (image - image.min()) / (image.max() - image.min())\n",
        "        # Scale Pixel Values\n",
        "        image = (image * 255).astype(np.uint8)\n",
        "        # Convert to gray scale\n",
        "        if image.ndim == 3:\n",
        "            image = image[:, :, image.shape[2] // 2]\n",
        "\n",
        "        # Convert NumPy array to PIL image and transform\n",
        "        image = Image.fromarray(image)\n",
        "        if self.transform:\n",
        "          image = self.transform(image)\n",
        "\n",
        "        # Get Label\n",
        "        if (row['DIAGNOSIS_GROUP'] == 'MCI_to_AD')|(row['DIAGNOSIS_GROUP'] == 'Normal_to_AD')|(row['DIAGNOSIS_GROUP'] == 'Only_AD'):\n",
        "          label = 1\n",
        "        else:\n",
        "          label = 0\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Define image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize((224, 224)),  # Resize to a standard size (e.g., for a CNN)\n",
        "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
        "    transforms.Normalize([0.5], [0.5])  # Normalize with mean and std\n",
        "])\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = MRIDataset(dataframe=full_train, root_dir=root_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Example of iterating over the dataloader\n",
        "for images, labels in dataloader:\n",
        "    print(images.shape, labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ghlyULHb7pVW",
        "outputId": "2cc3db4d-6aff-4917-a746-e201fa0c4a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 224, 224]) tensor([1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
            "        0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
            "        1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1])\n",
            "torch.Size([64, 1, 224, 224]) tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
            "        0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
            "        1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0])\n",
            "torch.Size([64, 1, 224, 224]) tensor([0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
            "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
            "        0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1])\n",
            "torch.Size([64, 1, 224, 224]) tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
            "        0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
            "        0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0])\n",
            "torch.Size([64, 1, 224, 224]) tensor([1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
            "        1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "        0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0])\n",
            "torch.Size([64, 1, 224, 224]) tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
            "        0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
            "        1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])\n",
            "torch.Size([7, 1, 224, 224]) tensor([0, 1, 1, 0, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = MRIDataset(full_test, root_dir=root_dir, transform=transform)\n",
        "test_loader = DataLoader(test_set, batch_size=64, shuffle=True)\n",
        "for images, labels in test_loader:\n",
        "    print(images.shape, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzZ9heR8BuYR",
        "outputId": "6ff81eb3-0a4a-4a4c-ea54-2870f3474488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 224, 224]) tensor([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
            "        1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
            "        1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1])\n",
            "torch.Size([64, 1, 224, 224]) tensor([1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
            "        0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
            "        0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1])\n",
            "torch.Size([64, 1, 224, 224]) tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
            "        1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
            "        0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0])\n",
            "torch.Size([62, 1, 224, 224]) tensor([0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
            "        1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
            "        1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Differencing"
      ],
      "metadata": {
        "id": "AwVgzqCBVI8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Sort the DataFrame by PTID and Visit\n",
        "# Assuming your dataframe contains columns ['PTID', 'Visit', 'Image Path', 'Label']\n",
        "def preprocess_and_sort(df):\n",
        "    # Sort the dataframe by PTID and Visit (assuming visits are in 'm06', 'm12', etc.)\n",
        "    df = df.sort_values(by=['Subject', 'Visit'])\n",
        "    return df\n",
        "\n",
        "# 2. Image differencing function\n",
        "def image_differencing(image1_path, image2_path):\n",
        "    # Open the two images\n",
        "    img1 = nib.load(image1_path).get_fdata()\n",
        "    img2 = nib.load(image2_path).get_fdata()\n",
        "    # Get middle slcie\n",
        "    img1_mid = img1[img1.shape[0] // 2, :, :]\n",
        "    img2_mid = img2[img2.shape[0] // 2, :, :]\n",
        "    # Normalize to 0,1\n",
        "    img1_mid = (img1_mid - img1_mid.min()) / (img1_mid.max() - img1_mid.min())\n",
        "    img2_mid = (img2_mid - img2_mid.min()) / (img2_mid.max() - img2_mid.min())\n",
        "    # Scale Pixel Values\n",
        "    image1 = (img1_mid * 255).astype(np.uint8)\n",
        "    image2 = (img2_mid * 255).astype(np.uint8)\n",
        "\n",
        "    # Resize to ensure matching shapes (e.g., 256x256)\n",
        "    target_size = (224, 224)  # Example size\n",
        "    img1_resized = Image.fromarray(image1).resize(target_size, Image.BILINEAR)\n",
        "    img2_resized = Image.fromarray(image2).resize(target_size, Image.BILINEAR)\n",
        "\n",
        "    # Perform image differencing (pixel-wise subtraction)\n",
        "    img_diff = np.abs(np.array(img1_resized) - np.array(img2_resized))\n",
        "\n",
        "    # Convert the difference array back to an image (in case you need to save or visualize it)\n",
        "    img_diff = Image.fromarray(img_diff)\n",
        "\n",
        "    return img_diff\n",
        "\n",
        "# 3. Dataset class for differenced images\n",
        "class ImageDifferenceDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            df (DataFrame): DataFrame containing columns ['Subject', 'Visit', 'FullPath', 'DIAGNOSIS_GROUP']\n",
        "            transform (callable, optional): Optional transform to be applied on an image.\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        self.data = self.create_image_diff_data()\n",
        "\n",
        "    def create_image_diff_data(self):\n",
        "        \"\"\"\n",
        "        Create the image differences for each PTID.\n",
        "        \"\"\"\n",
        "        data = []\n",
        "        ptids = self.df['Subject'].unique()\n",
        "        i=0\n",
        "        for ptid in ptids:\n",
        "            ptid_data = self.df[self.df['Subject'] == ptid]\n",
        "            ptid_data = ptid_data.drop_duplicates(subset=['Visit'])\n",
        "            if len(ptid_data) >= 3:\n",
        "              # For m06-bl difference (Baseline vs. 6 months)\n",
        "              m06_bl_img1 = ptid_data[ptid_data['Visit'] == 'sc']['FullPath'].values[0]\n",
        "              m06_bl_img2 = ptid_data[ptid_data['Visit'] == 'm06']['FullPath'].values[0]\n",
        "              m06_bl_diff = image_differencing(m06_bl_img1, m06_bl_img2)\n",
        "\n",
        "              # For m12-m06 difference (12 months vs. 6 months)\n",
        "              m12_m06_img1 = ptid_data[ptid_data['Visit'] == 'm06']['FullPath'].values[0]\n",
        "              m12_m06_img2 = ptid_data[ptid_data['Visit'] == 'm12']['FullPath'].values[0]\n",
        "              m12_m06_diff = image_differencing(m12_m06_img1, m12_m06_img2)\n",
        "              diagnosis_group = ptid_data['DIAGNOSIS_GROUP'].values[0]\n",
        "              if diagnosis_group in ['MCI_to_AD', 'Normal_to_AD', 'Only_AD']:\n",
        "                  label = 1\n",
        "              else:\n",
        "                  label = 0\n",
        "\n",
        "              # Append the differenced images and corresponding labels to the data list\n",
        "              data.append((m06_bl_diff, label))\n",
        "              data.append((m12_m06_diff, label))\n",
        "            else:\n",
        "              print(f'Not found for {ptid}')\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.data[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# 4. DataLoader with transformations\n",
        "diff_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "DYV6CH_s4ZuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Prep Test Image Diffing\n",
        "test_sorted = preprocess_and_sort(full_test)\n",
        "\n",
        "diff_testset = ImageDifferenceDataset(test_sorted, transform=diff_transform)\n",
        "\n",
        "diff_testloader = DataLoader(diff_testset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "JmyZ-TABcbjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27874ec1-ba02-4e38-fd08-8154fe45b40c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not found for 002_S_1070\n",
            "Not found for 005_S_0324\n",
            "Not found for 014_S_0520\n",
            "Not found for 021_S_0276\n",
            "Not found for 027_S_0120\n",
            "Not found for 027_S_0179\n",
            "Not found for 027_S_0307\n",
            "Not found for 027_S_0408\n",
            "Not found for 035_S_0156\n",
            "Not found for 041_S_0898\n",
            "Not found for 057_S_0474\n",
            "Not found for 057_S_0839\n",
            "Not found for 099_S_0551\n",
            "Not found for 114_S_0601\n",
            "Not found for 126_S_0784\n",
            "Not found for 126_S_0865\n",
            "Not found for 126_S_0891\n",
            "Not found for 127_S_0844\n",
            "Not found for 137_S_0443\n",
            "Not found for 137_S_0722\n",
            "Not found for 137_S_0973\n",
            "Not found for 137_S_1041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in diff_testloader:\n",
        "    print(images.shape, labels)"
      ],
      "metadata": {
        "id": "jrMtX68Zo0Co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Prep training Image Diffing\n",
        "train_sorted = preprocess_and_sort(full_train)\n",
        "\n",
        "# Step 2: Create Dataset\n",
        "diff_trainset = ImageDifferenceDataset(train_sorted, transform=diff_transform)\n",
        "\n",
        "# Step 3: Create DataLoader\n",
        "diff_trainloader = DataLoader(diff_trainset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrqRVGznYbXh",
        "outputId": "0d130bdd-ae18-4079-f09e-af8d2ceeaf94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not found for 005_S_0223\n",
            "Not found for 007_S_0293\n",
            "Not found for 011_S_0005\n",
            "Not found for 011_S_0010\n",
            "Not found for 011_S_0023\n",
            "Not found for 011_S_0183\n",
            "Not found for 011_S_0241\n",
            "Not found for 011_S_0861\n",
            "Not found for 011_S_1080\n",
            "Not found for 014_S_0328\n",
            "Not found for 014_S_0658\n",
            "Not found for 016_S_0538\n",
            "Not found for 016_S_0702\n",
            "Not found for 021_S_0141\n",
            "Not found for 021_S_0424\n",
            "Not found for 021_S_0753\n",
            "Not found for 027_S_0256\n",
            "Not found for 033_S_0516\n",
            "Not found for 033_S_0567\n",
            "Not found for 033_S_0906\n",
            "Not found for 033_S_0920\n",
            "Not found for 033_S_0922\n",
            "Not found for 035_S_0033\n",
            "Not found for 035_S_0292\n",
            "Not found for 036_S_0577\n",
            "Not found for 036_S_0656\n",
            "Not found for 036_S_0760\n",
            "Not found for 036_S_0813\n",
            "Not found for 041_S_0314\n",
            "Not found for 041_S_0679\n",
            "Not found for 057_S_0464\n",
            "Not found for 057_S_0934\n",
            "Not found for 099_S_0040\n",
            "Not found for 099_S_0291\n",
            "Not found for 099_S_0372\n",
            "Not found for 099_S_0534\n",
            "Not found for 126_S_0680\n",
            "Not found for 127_S_0259\n",
            "Not found for 127_S_0394\n",
            "Not found for 127_S_0431\n",
            "Not found for 136_S_0196\n",
            "Not found for 136_S_0299\n",
            "Not found for 137_S_0301\n",
            "Not found for 137_S_0366\n",
            "Not found for 137_S_0994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in diff_trainloader:\n",
        "    print(images.shape, labels)"
      ],
      "metadata": {
        "id": "ocKxlT14m_2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "kQPo1bPZVPn7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and Load Models"
      ],
      "metadata": {
        "id": "3Gim6jahVYYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Import Pretrained Models\n",
        "from torchvision import models\n",
        "def modify_resnet_for_grayscale(model):\n",
        "    model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "    return model\n",
        "def modify_vgg_for_grayscale(model):\n",
        "    model.features[0] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    return model\n",
        "models_dict = {\n",
        "    'resnet18': models.resnet18(pretrained=True),\n",
        "    'vgg11': models.vgg11(pretrained=True),\n",
        "    'densenet121': models.densenet121(pretrained=True)\n",
        "}"
      ],
      "metadata": {
        "id": "8ECLa9lxVg6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e92b282f-521f-41e9-a912-f3eecb8b2884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 176MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg11-8a719046.pth\" to /root/.cache/torch/hub/checkpoints/vgg11-8a719046.pth\n",
            "100%|██████████| 507M/507M [00:02<00:00, 220MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 154MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Simple CNN\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 56 * 56, 128)  # Adjust based on image size\n",
        "        self.fc2 = nn.Linear(128, 2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "a8IqZ0ES32Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Models"
      ],
      "metadata": {
        "id": "W2Lm7kQZVbVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_model(model, og_model_name, train_loader, val_loader, num_epochs, criterion, optimizer, device, metrics_df, model_save_dir, metrics_save_dir):\n",
        "    \"\"\"\n",
        "    Train and validate a model, save the best models and log the metrics into a dataframe.\n",
        "\n",
        "    Args:\n",
        "        model: PyTorch model (pretrained or custom).\n",
        "        train_loader: DataLoader for training data.\n",
        "        val_loader: DataLoader for validation data.\n",
        "        num_epochs: Number of training epochs.\n",
        "        criterion: Loss function (e.g., CrossEntropyLoss).\n",
        "        optimizer: Optimizer (e.g., Adam, SGD).\n",
        "        device: Device to run training on ('cuda' or 'cpu').\n",
        "        model_save_dir: Directory to save the best models.\n",
        "        metrics_df: DataFrame to store the metrics of the models.\n",
        "        metrics_save_dir: Directory to save the metrics dataframe.\n",
        "    \"\"\"\n",
        "    # Track the top 5 models by validation F1 score\n",
        "    top_models = []\n",
        "    os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "        running_loss = 0.0\n",
        "        all_preds, all_labels = [], []\n",
        "\n",
        "        # Training loop\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Back pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulate metrics\n",
        "            running_loss += loss.item()\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate training metrics\n",
        "        train_acc = accuracy_score(all_labels, all_preds)\n",
        "        train_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Training Loss: {running_loss:.4f} - Accuracy: {train_acc:.4f} - F1 Score: {train_f1:.4f}\")\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        val_preds, val_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for val_inputs, val_labels_batch in val_loader:\n",
        "                val_inputs, val_labels_batch = val_inputs.to(device), val_labels_batch.to(device)\n",
        "                val_outputs = model(val_inputs)\n",
        "                val_preds_batch = torch.argmax(val_outputs, dim=1)\n",
        "                val_preds.extend(val_preds_batch.cpu().numpy())\n",
        "                val_labels.extend(val_labels_batch.cpu().numpy())\n",
        "\n",
        "        # Calculate validation metrics\n",
        "        val_acc = accuracy_score(val_labels, val_preds)\n",
        "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
        "\n",
        "        print(f\"Validation Accuracy: {val_acc:.4f} - F1 Score: {val_f1:.4f}\")\n",
        "\n",
        "        # Save model if it is in top 5 by validation F1 score\n",
        "        top_models.append((val_f1, f\"{og_model_name}_{epoch+1}\", train_acc, train_f1, val_acc, val_f1))\n",
        "        top_models = sorted(top_models, key=lambda x: x[0], reverse=True)[:5]  # Keep top 5 models\n",
        "\n",
        "        for idx, (f1, model_name, _, _, _, _) in enumerate(top_models):\n",
        "            print(f\"Top {idx+1}: F1 Score = {f1:.4f}, Model = {model_name}\")\n",
        "\n",
        "        # Save the current model\n",
        "        model_save_path = os.path.join(model_save_dir, f\"{model_name}.pkl\")\n",
        "        torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "        # Record metrics of the top models\n",
        "        for f1, model_name, train_acc, train_f1, val_acc, val_f1 in top_models:\n",
        "            metrics_df = pd.concat([metrics_df, pd.DataFrame({\n",
        "                'Model': [model_name],\n",
        "                'Epoch': [epoch+1],\n",
        "                'Train Accuracy': [train_acc],\n",
        "                'Train F1': [train_f1],\n",
        "                'Test Accuracy': [val_acc],\n",
        "                'Test F1': [val_f1]\n",
        "            })], ignore_index=True)\n",
        "    print(\"Top 5 models saved:\")\n",
        "    for f1, model_name, _, _, _, _ in top_models:\n",
        "        print(f\"F1 Score: {f1:.4f} - Model: {model_name}\")\n",
        "\n",
        "    # Save metrics dataframe\n",
        "    metrics_df.to_csv(os.path.join(metrics_save_dir, 'model_metrics.csv'), index=False)\n",
        "    return metrics_df\n",
        "metrics_df = pd.DataFrame(columns=['Model', 'Epoch', 'Train Accuracy', 'Train F1', 'Test Accuracy', 'Test F1'])"
      ],
      "metadata": {
        "id": "vW1VvaHZVgUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "xdBlWv6RLlD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, model in models_dict.items():\n",
        "  torch.cuda.empty_cache()\n",
        "  print(f\"Training {model_name}...\")\n",
        "  if model_name == 'resnet18':\n",
        "    model = modify_resnet_for_grayscale(model)\n",
        "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "  elif model_name == 'vgg11':\n",
        "    model = modify_vgg_for_grayscale(model)\n",
        "    model.classifier[6] = nn.Linear(model.classifier[6].in_features, 2)\n",
        "  elif model_name == 'densenet121':\n",
        "    model = modify_vgg_for_grayscale(model)\n",
        "    model.classifier = nn.Linear(model.classifier.in_features, 2)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(device)\n",
        "  model = model.to(device)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
        "  num_epochs = 30\n",
        "  metrics_df = train_model(model,\n",
        "                          model_name,\n",
        "                          diff_trainloader,\n",
        "                          diff_testloader,\n",
        "                          num_epochs,\n",
        "                          criterion,\n",
        "                          optimizer,\n",
        "                          device,\n",
        "                          metrics_df,\n",
        "                          \"/content/drive/MyDrive/PBHLT7120_Project/ProjectMaterials/Models/ClassifiersOne/\",\n",
        "                          \"/content/drive/MyDrive/PBHLT7120_Project/ProjectMaterials/Models/\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBvoqd-g-Kjz",
        "outputId": "78c7f955-baed-49e6-f05a-22844b75df5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training resnet18...\n",
            "cuda\n",
            "Epoch 1/30 - Training Loss: 2.6898 - Accuracy: 0.3684 - F1 Score: 0.2926\n",
            "Validation Accuracy: 0.5455 - F1 Score: 0.4006\n",
            "Top 1: F1 Score = 0.4006, Model = resnet18_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-69-57719eddf72a>:81: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  metrics_df = pd.concat([metrics_df, pd.DataFrame({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - Training Loss: 2.3150 - Accuracy: 0.4605 - F1 Score: 0.3623\n",
            "Validation Accuracy: 0.5364 - F1 Score: 0.4722\n",
            "Top 1: F1 Score = 0.4722, Model = resnet18_2\n",
            "Top 2: F1 Score = 0.4006, Model = resnet18_1\n",
            "Epoch 3/30 - Training Loss: 2.0296 - Accuracy: 0.5461 - F1 Score: 0.4727\n",
            "Validation Accuracy: 0.5000 - F1 Score: 0.4927\n",
            "Top 1: F1 Score = 0.4927, Model = resnet18_3\n",
            "Top 2: F1 Score = 0.4722, Model = resnet18_2\n",
            "Top 3: F1 Score = 0.4006, Model = resnet18_1\n",
            "Epoch 4/30 - Training Loss: 1.7241 - Accuracy: 0.6645 - F1 Score: 0.6294\n",
            "Validation Accuracy: 0.4727 - F1 Score: 0.4578\n",
            "Top 1: F1 Score = 0.4927, Model = resnet18_3\n",
            "Top 2: F1 Score = 0.4722, Model = resnet18_2\n",
            "Top 3: F1 Score = 0.4578, Model = resnet18_4\n",
            "Top 4: F1 Score = 0.4006, Model = resnet18_1\n",
            "Epoch 5/30 - Training Loss: 1.7024 - Accuracy: 0.7237 - F1 Score: 0.7054\n",
            "Validation Accuracy: 0.4636 - F1 Score: 0.4024\n",
            "Top 1: F1 Score = 0.4927, Model = resnet18_3\n",
            "Top 2: F1 Score = 0.4722, Model = resnet18_2\n",
            "Top 3: F1 Score = 0.4578, Model = resnet18_4\n",
            "Top 4: F1 Score = 0.4024, Model = resnet18_5\n",
            "Top 5: F1 Score = 0.4006, Model = resnet18_1\n",
            "Epoch 6/30 - Training Loss: 1.3537 - Accuracy: 0.8618 - F1 Score: 0.8597\n",
            "Validation Accuracy: 0.4909 - F1 Score: 0.4213\n",
            "Top 1: F1 Score = 0.4927, Model = resnet18_3\n",
            "Top 2: F1 Score = 0.4722, Model = resnet18_2\n",
            "Top 3: F1 Score = 0.4578, Model = resnet18_4\n",
            "Top 4: F1 Score = 0.4213, Model = resnet18_6\n",
            "Top 5: F1 Score = 0.4024, Model = resnet18_5\n",
            "Epoch 7/30 - Training Loss: 1.2466 - Accuracy: 0.9276 - F1 Score: 0.9274\n",
            "Validation Accuracy: 0.4818 - F1 Score: 0.4068\n",
            "Top 1: F1 Score = 0.4927, Model = resnet18_3\n",
            "Top 2: F1 Score = 0.4722, Model = resnet18_2\n",
            "Top 3: F1 Score = 0.4578, Model = resnet18_4\n",
            "Top 4: F1 Score = 0.4213, Model = resnet18_6\n",
            "Top 5: F1 Score = 0.4068, Model = resnet18_7\n",
            "Epoch 8/30 - Training Loss: 1.0714 - Accuracy: 0.9671 - F1 Score: 0.9671\n",
            "Validation Accuracy: 0.4909 - F1 Score: 0.4038\n",
            "Top 1: F1 Score = 0.4927, Model = resnet18_3\n",
            "Top 2: F1 Score = 0.4722, Model = resnet18_2\n",
            "Top 3: F1 Score = 0.4578, Model = resnet18_4\n",
            "Top 4: F1 Score = 0.4213, Model = resnet18_6\n",
            "Top 5: F1 Score = 0.4068, Model = resnet18_7\n",
            "Epoch 9/30 - Training Loss: 0.9728 - Accuracy: 0.9803 - F1 Score: 0.9803\n",
            "Validation Accuracy: 0.4909 - F1 Score: 0.4129\n",
            "Top 1: F1 Score = 0.4927, Model = resnet18_3\n",
            "Top 2: F1 Score = 0.4722, Model = resnet18_2\n",
            "Top 3: F1 Score = 0.4578, Model = resnet18_4\n",
            "Top 4: F1 Score = 0.4213, Model = resnet18_6\n",
            "Top 5: F1 Score = 0.4129, Model = resnet18_9\n",
            "Epoch 10/30 - Training Loss: 0.9330 - Accuracy: 0.9868 - F1 Score: 0.9868\n",
            "Validation Accuracy: 0.5182 - F1 Score: 0.4561\n",
            "Top 1: F1 Score = 0.4927, Model = resnet18_3\n",
            "Top 2: F1 Score = 0.4722, Model = resnet18_2\n",
            "Top 3: F1 Score = 0.4578, Model = resnet18_4\n",
            "Top 4: F1 Score = 0.4561, Model = resnet18_10\n",
            "Top 5: F1 Score = 0.4213, Model = resnet18_6\n",
            "Epoch 11/30 - Training Loss: 0.8088 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.4565\n",
            "Top 1: F1 Score = 0.4927, Model = resnet18_3\n",
            "Top 2: F1 Score = 0.4722, Model = resnet18_2\n",
            "Top 3: F1 Score = 0.4578, Model = resnet18_4\n",
            "Top 4: F1 Score = 0.4565, Model = resnet18_11\n",
            "Top 5: F1 Score = 0.4561, Model = resnet18_10\n",
            "Epoch 12/30 - Training Loss: 0.6971 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.4938\n",
            "Top 1: F1 Score = 0.4938, Model = resnet18_12\n",
            "Top 2: F1 Score = 0.4927, Model = resnet18_3\n",
            "Top 3: F1 Score = 0.4722, Model = resnet18_2\n",
            "Top 4: F1 Score = 0.4578, Model = resnet18_4\n",
            "Top 5: F1 Score = 0.4565, Model = resnet18_11\n",
            "Epoch 13/30 - Training Loss: 0.7492 - Accuracy: 0.9934 - F1 Score: 0.9934\n",
            "Validation Accuracy: 0.5182 - F1 Score: 0.4814\n",
            "Top 1: F1 Score = 0.4938, Model = resnet18_12\n",
            "Top 2: F1 Score = 0.4927, Model = resnet18_3\n",
            "Top 3: F1 Score = 0.4814, Model = resnet18_13\n",
            "Top 4: F1 Score = 0.4722, Model = resnet18_2\n",
            "Top 5: F1 Score = 0.4578, Model = resnet18_4\n",
            "Epoch 14/30 - Training Loss: 0.6113 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5182 - F1 Score: 0.4913\n",
            "Top 1: F1 Score = 0.4938, Model = resnet18_12\n",
            "Top 2: F1 Score = 0.4927, Model = resnet18_3\n",
            "Top 3: F1 Score = 0.4913, Model = resnet18_14\n",
            "Top 4: F1 Score = 0.4814, Model = resnet18_13\n",
            "Top 5: F1 Score = 0.4722, Model = resnet18_2\n",
            "Epoch 15/30 - Training Loss: 0.5111 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5182 - F1 Score: 0.4956\n",
            "Top 1: F1 Score = 0.4956, Model = resnet18_15\n",
            "Top 2: F1 Score = 0.4938, Model = resnet18_12\n",
            "Top 3: F1 Score = 0.4927, Model = resnet18_3\n",
            "Top 4: F1 Score = 0.4913, Model = resnet18_14\n",
            "Top 5: F1 Score = 0.4814, Model = resnet18_13\n",
            "Epoch 16/30 - Training Loss: 0.4766 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5182 - F1 Score: 0.4995\n",
            "Top 1: F1 Score = 0.4995, Model = resnet18_16\n",
            "Top 2: F1 Score = 0.4956, Model = resnet18_15\n",
            "Top 3: F1 Score = 0.4938, Model = resnet18_12\n",
            "Top 4: F1 Score = 0.4927, Model = resnet18_3\n",
            "Top 5: F1 Score = 0.4913, Model = resnet18_14\n",
            "Epoch 17/30 - Training Loss: 0.4384 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.4952\n",
            "Top 1: F1 Score = 0.4995, Model = resnet18_16\n",
            "Top 2: F1 Score = 0.4956, Model = resnet18_15\n",
            "Top 3: F1 Score = 0.4952, Model = resnet18_17\n",
            "Top 4: F1 Score = 0.4938, Model = resnet18_12\n",
            "Top 5: F1 Score = 0.4927, Model = resnet18_3\n",
            "Epoch 18/30 - Training Loss: 0.3973 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.4952\n",
            "Top 1: F1 Score = 0.4995, Model = resnet18_16\n",
            "Top 2: F1 Score = 0.4956, Model = resnet18_15\n",
            "Top 3: F1 Score = 0.4952, Model = resnet18_17\n",
            "Top 4: F1 Score = 0.4952, Model = resnet18_18\n",
            "Top 5: F1 Score = 0.4938, Model = resnet18_12\n",
            "Epoch 19/30 - Training Loss: 0.3941 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.4909 - F1 Score: 0.4869\n",
            "Top 1: F1 Score = 0.4995, Model = resnet18_16\n",
            "Top 2: F1 Score = 0.4956, Model = resnet18_15\n",
            "Top 3: F1 Score = 0.4952, Model = resnet18_17\n",
            "Top 4: F1 Score = 0.4952, Model = resnet18_18\n",
            "Top 5: F1 Score = 0.4938, Model = resnet18_12\n",
            "Epoch 20/30 - Training Loss: 0.3103 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5000 - F1 Score: 0.4969\n",
            "Top 1: F1 Score = 0.4995, Model = resnet18_16\n",
            "Top 2: F1 Score = 0.4969, Model = resnet18_20\n",
            "Top 3: F1 Score = 0.4956, Model = resnet18_15\n",
            "Top 4: F1 Score = 0.4952, Model = resnet18_17\n",
            "Top 5: F1 Score = 0.4952, Model = resnet18_18\n",
            "Epoch 21/30 - Training Loss: 0.2812 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5273\n",
            "Top 1: F1 Score = 0.5273, Model = resnet18_21\n",
            "Top 2: F1 Score = 0.4995, Model = resnet18_16\n",
            "Top 3: F1 Score = 0.4969, Model = resnet18_20\n",
            "Top 4: F1 Score = 0.4956, Model = resnet18_15\n",
            "Top 5: F1 Score = 0.4952, Model = resnet18_17\n",
            "Epoch 22/30 - Training Loss: 0.2850 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5251\n",
            "Top 1: F1 Score = 0.5273, Model = resnet18_21\n",
            "Top 2: F1 Score = 0.5251, Model = resnet18_22\n",
            "Top 3: F1 Score = 0.4995, Model = resnet18_16\n",
            "Top 4: F1 Score = 0.4969, Model = resnet18_20\n",
            "Top 5: F1 Score = 0.4956, Model = resnet18_15\n",
            "Epoch 23/30 - Training Loss: 0.2554 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.4909 - F1 Score: 0.4848\n",
            "Top 1: F1 Score = 0.5273, Model = resnet18_21\n",
            "Top 2: F1 Score = 0.5251, Model = resnet18_22\n",
            "Top 3: F1 Score = 0.4995, Model = resnet18_16\n",
            "Top 4: F1 Score = 0.4969, Model = resnet18_20\n",
            "Top 5: F1 Score = 0.4956, Model = resnet18_15\n",
            "Epoch 24/30 - Training Loss: 0.2421 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5000 - F1 Score: 0.4951\n",
            "Top 1: F1 Score = 0.5273, Model = resnet18_21\n",
            "Top 2: F1 Score = 0.5251, Model = resnet18_22\n",
            "Top 3: F1 Score = 0.4995, Model = resnet18_16\n",
            "Top 4: F1 Score = 0.4969, Model = resnet18_20\n",
            "Top 5: F1 Score = 0.4956, Model = resnet18_15\n",
            "Epoch 25/30 - Training Loss: 0.2111 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.5052\n",
            "Top 1: F1 Score = 0.5273, Model = resnet18_21\n",
            "Top 2: F1 Score = 0.5251, Model = resnet18_22\n",
            "Top 3: F1 Score = 0.5052, Model = resnet18_25\n",
            "Top 4: F1 Score = 0.4995, Model = resnet18_16\n",
            "Top 5: F1 Score = 0.4969, Model = resnet18_20\n",
            "Epoch 26/30 - Training Loss: 0.1902 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5263\n",
            "Top 1: F1 Score = 0.5273, Model = resnet18_21\n",
            "Top 2: F1 Score = 0.5263, Model = resnet18_26\n",
            "Top 3: F1 Score = 0.5251, Model = resnet18_22\n",
            "Top 4: F1 Score = 0.5052, Model = resnet18_25\n",
            "Top 5: F1 Score = 0.4995, Model = resnet18_16\n",
            "Epoch 27/30 - Training Loss: 0.2062 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5182 - F1 Score: 0.5166\n",
            "Top 1: F1 Score = 0.5273, Model = resnet18_21\n",
            "Top 2: F1 Score = 0.5263, Model = resnet18_26\n",
            "Top 3: F1 Score = 0.5251, Model = resnet18_22\n",
            "Top 4: F1 Score = 0.5166, Model = resnet18_27\n",
            "Top 5: F1 Score = 0.5052, Model = resnet18_25\n",
            "Epoch 28/30 - Training Loss: 0.2025 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5364 - F1 Score: 0.5372\n",
            "Top 1: F1 Score = 0.5372, Model = resnet18_28\n",
            "Top 2: F1 Score = 0.5273, Model = resnet18_21\n",
            "Top 3: F1 Score = 0.5263, Model = resnet18_26\n",
            "Top 4: F1 Score = 0.5251, Model = resnet18_22\n",
            "Top 5: F1 Score = 0.5166, Model = resnet18_27\n",
            "Epoch 29/30 - Training Loss: 0.2199 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5364 - F1 Score: 0.5372\n",
            "Top 1: F1 Score = 0.5372, Model = resnet18_29\n",
            "Top 2: F1 Score = 0.5372, Model = resnet18_28\n",
            "Top 3: F1 Score = 0.5273, Model = resnet18_21\n",
            "Top 4: F1 Score = 0.5263, Model = resnet18_26\n",
            "Top 5: F1 Score = 0.5251, Model = resnet18_22\n",
            "Epoch 30/30 - Training Loss: 0.1758 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5279\n",
            "Top 1: F1 Score = 0.5372, Model = resnet18_29\n",
            "Top 2: F1 Score = 0.5372, Model = resnet18_28\n",
            "Top 3: F1 Score = 0.5279, Model = resnet18_30\n",
            "Top 4: F1 Score = 0.5273, Model = resnet18_21\n",
            "Top 5: F1 Score = 0.5263, Model = resnet18_26\n",
            "Top 5 models saved:\n",
            "F1 Score: 0.5372 - Model: resnet18_29\n",
            "F1 Score: 0.5372 - Model: resnet18_28\n",
            "F1 Score: 0.5279 - Model: resnet18_30\n",
            "F1 Score: 0.5273 - Model: resnet18_21\n",
            "F1 Score: 0.5263 - Model: resnet18_26\n",
            "Training vgg11...\n",
            "cuda\n",
            "Epoch 1/30 - Training Loss: 2.2853 - Accuracy: 0.5132 - F1 Score: 0.5047\n",
            "Validation Accuracy: 0.4636 - F1 Score: 0.4619\n",
            "Top 1: F1 Score = 0.4619, Model = vgg11_1\n",
            "Epoch 2/30 - Training Loss: 2.0627 - Accuracy: 0.5066 - F1 Score: 0.5056\n",
            "Validation Accuracy: 0.4727 - F1 Score: 0.4734\n",
            "Top 1: F1 Score = 0.4734, Model = vgg11_2\n",
            "Top 2: F1 Score = 0.4619, Model = vgg11_1\n",
            "Epoch 3/30 - Training Loss: 2.0041 - Accuracy: 0.5658 - F1 Score: 0.5621\n",
            "Validation Accuracy: 0.4727 - F1 Score: 0.4727\n",
            "Top 1: F1 Score = 0.4734, Model = vgg11_2\n",
            "Top 2: F1 Score = 0.4727, Model = vgg11_3\n",
            "Top 3: F1 Score = 0.4619, Model = vgg11_1\n",
            "Epoch 4/30 - Training Loss: 1.8047 - Accuracy: 0.6513 - F1 Score: 0.6479\n",
            "Validation Accuracy: 0.5000 - F1 Score: 0.5004\n",
            "Top 1: F1 Score = 0.5004, Model = vgg11_4\n",
            "Top 2: F1 Score = 0.4734, Model = vgg11_2\n",
            "Top 3: F1 Score = 0.4727, Model = vgg11_3\n",
            "Top 4: F1 Score = 0.4619, Model = vgg11_1\n",
            "Epoch 5/30 - Training Loss: 1.7726 - Accuracy: 0.6842 - F1 Score: 0.6823\n",
            "Validation Accuracy: 0.4818 - F1 Score: 0.4829\n",
            "Top 1: F1 Score = 0.5004, Model = vgg11_4\n",
            "Top 2: F1 Score = 0.4829, Model = vgg11_5\n",
            "Top 3: F1 Score = 0.4734, Model = vgg11_2\n",
            "Top 4: F1 Score = 0.4727, Model = vgg11_3\n",
            "Top 5: F1 Score = 0.4619, Model = vgg11_1\n",
            "Epoch 6/30 - Training Loss: 1.6656 - Accuracy: 0.7237 - F1 Score: 0.7225\n",
            "Validation Accuracy: 0.4909 - F1 Score: 0.4919\n",
            "Top 1: F1 Score = 0.5004, Model = vgg11_4\n",
            "Top 2: F1 Score = 0.4919, Model = vgg11_6\n",
            "Top 3: F1 Score = 0.4829, Model = vgg11_5\n",
            "Top 4: F1 Score = 0.4734, Model = vgg11_2\n",
            "Top 5: F1 Score = 0.4727, Model = vgg11_3\n",
            "Epoch 7/30 - Training Loss: 1.6145 - Accuracy: 0.7434 - F1 Score: 0.7416\n",
            "Validation Accuracy: 0.4818 - F1 Score: 0.4827\n",
            "Top 1: F1 Score = 0.5004, Model = vgg11_4\n",
            "Top 2: F1 Score = 0.4919, Model = vgg11_6\n",
            "Top 3: F1 Score = 0.4829, Model = vgg11_5\n",
            "Top 4: F1 Score = 0.4827, Model = vgg11_7\n",
            "Top 5: F1 Score = 0.4734, Model = vgg11_2\n",
            "Epoch 8/30 - Training Loss: 1.7207 - Accuracy: 0.7039 - F1 Score: 0.7034\n",
            "Validation Accuracy: 0.4636 - F1 Score: 0.4646\n",
            "Top 1: F1 Score = 0.5004, Model = vgg11_4\n",
            "Top 2: F1 Score = 0.4919, Model = vgg11_6\n",
            "Top 3: F1 Score = 0.4829, Model = vgg11_5\n",
            "Top 4: F1 Score = 0.4827, Model = vgg11_7\n",
            "Top 5: F1 Score = 0.4734, Model = vgg11_2\n",
            "Epoch 9/30 - Training Loss: 1.5754 - Accuracy: 0.7368 - F1 Score: 0.7357\n",
            "Validation Accuracy: 0.4545 - F1 Score: 0.4545\n",
            "Top 1: F1 Score = 0.5004, Model = vgg11_4\n",
            "Top 2: F1 Score = 0.4919, Model = vgg11_6\n",
            "Top 3: F1 Score = 0.4829, Model = vgg11_5\n",
            "Top 4: F1 Score = 0.4827, Model = vgg11_7\n",
            "Top 5: F1 Score = 0.4734, Model = vgg11_2\n",
            "Epoch 10/30 - Training Loss: 1.3896 - Accuracy: 0.7961 - F1 Score: 0.7954\n",
            "Validation Accuracy: 0.4636 - F1 Score: 0.4646\n",
            "Top 1: F1 Score = 0.5004, Model = vgg11_4\n",
            "Top 2: F1 Score = 0.4919, Model = vgg11_6\n",
            "Top 3: F1 Score = 0.4829, Model = vgg11_5\n",
            "Top 4: F1 Score = 0.4827, Model = vgg11_7\n",
            "Top 5: F1 Score = 0.4734, Model = vgg11_2\n",
            "Epoch 11/30 - Training Loss: 1.3978 - Accuracy: 0.7829 - F1 Score: 0.7829\n",
            "Validation Accuracy: 0.4818 - F1 Score: 0.4829\n",
            "Top 1: F1 Score = 0.5004, Model = vgg11_4\n",
            "Top 2: F1 Score = 0.4919, Model = vgg11_6\n",
            "Top 3: F1 Score = 0.4829, Model = vgg11_5\n",
            "Top 4: F1 Score = 0.4829, Model = vgg11_11\n",
            "Top 5: F1 Score = 0.4827, Model = vgg11_7\n",
            "Epoch 12/30 - Training Loss: 1.3752 - Accuracy: 0.8092 - F1 Score: 0.8090\n",
            "Validation Accuracy: 0.4818 - F1 Score: 0.4829\n",
            "Top 1: F1 Score = 0.5004, Model = vgg11_4\n",
            "Top 2: F1 Score = 0.4919, Model = vgg11_6\n",
            "Top 3: F1 Score = 0.4829, Model = vgg11_5\n",
            "Top 4: F1 Score = 0.4829, Model = vgg11_11\n",
            "Top 5: F1 Score = 0.4829, Model = vgg11_12\n",
            "Epoch 13/30 - Training Loss: 1.2340 - Accuracy: 0.8684 - F1 Score: 0.8684\n",
            "Validation Accuracy: 0.5000 - F1 Score: 0.5004\n",
            "Top 1: F1 Score = 0.5004, Model = vgg11_4\n",
            "Top 2: F1 Score = 0.5004, Model = vgg11_13\n",
            "Top 3: F1 Score = 0.4919, Model = vgg11_6\n",
            "Top 4: F1 Score = 0.4829, Model = vgg11_5\n",
            "Top 5: F1 Score = 0.4829, Model = vgg11_11\n",
            "Epoch 14/30 - Training Loss: 1.2777 - Accuracy: 0.8355 - F1 Score: 0.8355\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.5091\n",
            "Top 1: F1 Score = 0.5091, Model = vgg11_14\n",
            "Top 2: F1 Score = 0.5004, Model = vgg11_4\n",
            "Top 3: F1 Score = 0.5004, Model = vgg11_13\n",
            "Top 4: F1 Score = 0.4919, Model = vgg11_6\n",
            "Top 5: F1 Score = 0.4829, Model = vgg11_5\n",
            "Epoch 15/30 - Training Loss: 1.2255 - Accuracy: 0.8224 - F1 Score: 0.8220\n",
            "Validation Accuracy: 0.4909 - F1 Score: 0.4916\n",
            "Top 1: F1 Score = 0.5091, Model = vgg11_14\n",
            "Top 2: F1 Score = 0.5004, Model = vgg11_4\n",
            "Top 3: F1 Score = 0.5004, Model = vgg11_13\n",
            "Top 4: F1 Score = 0.4919, Model = vgg11_6\n",
            "Top 5: F1 Score = 0.4916, Model = vgg11_15\n",
            "Epoch 16/30 - Training Loss: 1.0239 - Accuracy: 0.8487 - F1 Score: 0.8485\n",
            "Validation Accuracy: 0.4909 - F1 Score: 0.4848\n",
            "Top 1: F1 Score = 0.5091, Model = vgg11_14\n",
            "Top 2: F1 Score = 0.5004, Model = vgg11_4\n",
            "Top 3: F1 Score = 0.5004, Model = vgg11_13\n",
            "Top 4: F1 Score = 0.4919, Model = vgg11_6\n",
            "Top 5: F1 Score = 0.4916, Model = vgg11_15\n",
            "Epoch 17/30 - Training Loss: 1.0239 - Accuracy: 0.8618 - F1 Score: 0.8619\n",
            "Validation Accuracy: 0.5000 - F1 Score: 0.4969\n",
            "Top 1: F1 Score = 0.5091, Model = vgg11_14\n",
            "Top 2: F1 Score = 0.5004, Model = vgg11_4\n",
            "Top 3: F1 Score = 0.5004, Model = vgg11_13\n",
            "Top 4: F1 Score = 0.4969, Model = vgg11_17\n",
            "Top 5: F1 Score = 0.4919, Model = vgg11_6\n",
            "Epoch 18/30 - Training Loss: 0.8910 - Accuracy: 0.8553 - F1 Score: 0.8553\n",
            "Validation Accuracy: 0.4818 - F1 Score: 0.4801\n",
            "Top 1: F1 Score = 0.5091, Model = vgg11_14\n",
            "Top 2: F1 Score = 0.5004, Model = vgg11_4\n",
            "Top 3: F1 Score = 0.5004, Model = vgg11_13\n",
            "Top 4: F1 Score = 0.4969, Model = vgg11_17\n",
            "Top 5: F1 Score = 0.4919, Model = vgg11_6\n",
            "Epoch 19/30 - Training Loss: 0.8916 - Accuracy: 0.8947 - F1 Score: 0.8948\n",
            "Validation Accuracy: 0.5000 - F1 Score: 0.4969\n",
            "Top 1: F1 Score = 0.5091, Model = vgg11_14\n",
            "Top 2: F1 Score = 0.5004, Model = vgg11_4\n",
            "Top 3: F1 Score = 0.5004, Model = vgg11_13\n",
            "Top 4: F1 Score = 0.4969, Model = vgg11_17\n",
            "Top 5: F1 Score = 0.4969, Model = vgg11_19\n",
            "Epoch 20/30 - Training Loss: 0.7974 - Accuracy: 0.9211 - F1 Score: 0.9210\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5279\n",
            "Top 1: F1 Score = 0.5279, Model = vgg11_20\n",
            "Top 2: F1 Score = 0.5091, Model = vgg11_14\n",
            "Top 3: F1 Score = 0.5004, Model = vgg11_4\n",
            "Top 4: F1 Score = 0.5004, Model = vgg11_13\n",
            "Top 5: F1 Score = 0.4969, Model = vgg11_17\n",
            "Epoch 21/30 - Training Loss: 0.7659 - Accuracy: 0.9408 - F1 Score: 0.9408\n",
            "Validation Accuracy: 0.5364 - F1 Score: 0.5372\n",
            "Top 1: F1 Score = 0.5372, Model = vgg11_21\n",
            "Top 2: F1 Score = 0.5279, Model = vgg11_20\n",
            "Top 3: F1 Score = 0.5091, Model = vgg11_14\n",
            "Top 4: F1 Score = 0.5004, Model = vgg11_4\n",
            "Top 5: F1 Score = 0.5004, Model = vgg11_13\n",
            "Epoch 22/30 - Training Loss: 0.7623 - Accuracy: 0.9079 - F1 Score: 0.9078\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5263\n",
            "Top 1: F1 Score = 0.5372, Model = vgg11_21\n",
            "Top 2: F1 Score = 0.5279, Model = vgg11_20\n",
            "Top 3: F1 Score = 0.5263, Model = vgg11_22\n",
            "Top 4: F1 Score = 0.5091, Model = vgg11_14\n",
            "Top 5: F1 Score = 0.5004, Model = vgg11_4\n",
            "Epoch 23/30 - Training Loss: 0.6694 - Accuracy: 0.9539 - F1 Score: 0.9539\n",
            "Validation Accuracy: 0.5364 - F1 Score: 0.5373\n",
            "Top 1: F1 Score = 0.5373, Model = vgg11_23\n",
            "Top 2: F1 Score = 0.5372, Model = vgg11_21\n",
            "Top 3: F1 Score = 0.5279, Model = vgg11_20\n",
            "Top 4: F1 Score = 0.5263, Model = vgg11_22\n",
            "Top 5: F1 Score = 0.5091, Model = vgg11_14\n",
            "Epoch 24/30 - Training Loss: 0.5978 - Accuracy: 0.9408 - F1 Score: 0.9408\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5273\n",
            "Top 1: F1 Score = 0.5373, Model = vgg11_23\n",
            "Top 2: F1 Score = 0.5372, Model = vgg11_21\n",
            "Top 3: F1 Score = 0.5279, Model = vgg11_20\n",
            "Top 4: F1 Score = 0.5273, Model = vgg11_24\n",
            "Top 5: F1 Score = 0.5263, Model = vgg11_22\n",
            "Epoch 25/30 - Training Loss: 0.5155 - Accuracy: 0.9474 - F1 Score: 0.9473\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.5081\n",
            "Top 1: F1 Score = 0.5373, Model = vgg11_23\n",
            "Top 2: F1 Score = 0.5372, Model = vgg11_21\n",
            "Top 3: F1 Score = 0.5279, Model = vgg11_20\n",
            "Top 4: F1 Score = 0.5273, Model = vgg11_24\n",
            "Top 5: F1 Score = 0.5263, Model = vgg11_22\n",
            "Epoch 26/30 - Training Loss: 0.4956 - Accuracy: 0.9539 - F1 Score: 0.9539\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.5068\n",
            "Top 1: F1 Score = 0.5373, Model = vgg11_23\n",
            "Top 2: F1 Score = 0.5372, Model = vgg11_21\n",
            "Top 3: F1 Score = 0.5279, Model = vgg11_20\n",
            "Top 4: F1 Score = 0.5273, Model = vgg11_24\n",
            "Top 5: F1 Score = 0.5263, Model = vgg11_22\n",
            "Epoch 27/30 - Training Loss: 0.4776 - Accuracy: 0.9671 - F1 Score: 0.9671\n",
            "Validation Accuracy: 0.5182 - F1 Score: 0.5185\n",
            "Top 1: F1 Score = 0.5373, Model = vgg11_23\n",
            "Top 2: F1 Score = 0.5372, Model = vgg11_21\n",
            "Top 3: F1 Score = 0.5279, Model = vgg11_20\n",
            "Top 4: F1 Score = 0.5273, Model = vgg11_24\n",
            "Top 5: F1 Score = 0.5263, Model = vgg11_22\n",
            "Epoch 28/30 - Training Loss: 0.3886 - Accuracy: 0.9671 - F1 Score: 0.9671\n",
            "Validation Accuracy: 0.5182 - F1 Score: 0.5177\n",
            "Top 1: F1 Score = 0.5373, Model = vgg11_23\n",
            "Top 2: F1 Score = 0.5372, Model = vgg11_21\n",
            "Top 3: F1 Score = 0.5279, Model = vgg11_20\n",
            "Top 4: F1 Score = 0.5273, Model = vgg11_24\n",
            "Top 5: F1 Score = 0.5263, Model = vgg11_22\n",
            "Epoch 29/30 - Training Loss: 0.3583 - Accuracy: 0.9605 - F1 Score: 0.9605\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5273\n",
            "Top 1: F1 Score = 0.5373, Model = vgg11_23\n",
            "Top 2: F1 Score = 0.5372, Model = vgg11_21\n",
            "Top 3: F1 Score = 0.5279, Model = vgg11_20\n",
            "Top 4: F1 Score = 0.5273, Model = vgg11_24\n",
            "Top 5: F1 Score = 0.5273, Model = vgg11_29\n",
            "Epoch 30/30 - Training Loss: 0.2880 - Accuracy: 0.9737 - F1 Score: 0.9737\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5273\n",
            "Top 1: F1 Score = 0.5373, Model = vgg11_23\n",
            "Top 2: F1 Score = 0.5372, Model = vgg11_21\n",
            "Top 3: F1 Score = 0.5279, Model = vgg11_20\n",
            "Top 4: F1 Score = 0.5273, Model = vgg11_24\n",
            "Top 5: F1 Score = 0.5273, Model = vgg11_29\n",
            "Top 5 models saved:\n",
            "F1 Score: 0.5373 - Model: vgg11_23\n",
            "F1 Score: 0.5372 - Model: vgg11_21\n",
            "F1 Score: 0.5279 - Model: vgg11_20\n",
            "F1 Score: 0.5273 - Model: vgg11_24\n",
            "F1 Score: 0.5273 - Model: vgg11_29\n",
            "Training densenet121...\n",
            "cuda\n",
            "Epoch 1/30 - Training Loss: 2.5327 - Accuracy: 0.4868 - F1 Score: 0.3188\n",
            "Validation Accuracy: 0.5455 - F1 Score: 0.3850\n",
            "Top 1: F1 Score = 0.3850, Model = densenet121_1\n",
            "Epoch 2/30 - Training Loss: 2.2058 - Accuracy: 0.4868 - F1 Score: 0.3188\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.3950\n",
            "Top 1: F1 Score = 0.3950, Model = densenet121_2\n",
            "Top 2: F1 Score = 0.3850, Model = densenet121_1\n",
            "Epoch 3/30 - Training Loss: 2.0037 - Accuracy: 0.4868 - F1 Score: 0.3188\n",
            "Validation Accuracy: 0.4636 - F1 Score: 0.3444\n",
            "Top 1: F1 Score = 0.3950, Model = densenet121_2\n",
            "Top 2: F1 Score = 0.3850, Model = densenet121_1\n",
            "Top 3: F1 Score = 0.3444, Model = densenet121_3\n",
            "Epoch 4/30 - Training Loss: 1.8611 - Accuracy: 0.4868 - F1 Score: 0.3188\n",
            "Validation Accuracy: 0.4545 - F1 Score: 0.2841\n",
            "Top 1: F1 Score = 0.3950, Model = densenet121_2\n",
            "Top 2: F1 Score = 0.3850, Model = densenet121_1\n",
            "Top 3: F1 Score = 0.3444, Model = densenet121_3\n",
            "Top 4: F1 Score = 0.2841, Model = densenet121_4\n",
            "Epoch 5/30 - Training Loss: 1.7081 - Accuracy: 0.5066 - F1 Score: 0.3611\n",
            "Validation Accuracy: 0.4545 - F1 Score: 0.2841\n",
            "Top 1: F1 Score = 0.3950, Model = densenet121_2\n",
            "Top 2: F1 Score = 0.3850, Model = densenet121_1\n",
            "Top 3: F1 Score = 0.3444, Model = densenet121_3\n",
            "Top 4: F1 Score = 0.2841, Model = densenet121_4\n",
            "Top 5: F1 Score = 0.2841, Model = densenet121_5\n",
            "Epoch 6/30 - Training Loss: 1.5724 - Accuracy: 0.5658 - F1 Score: 0.4735\n",
            "Validation Accuracy: 0.4545 - F1 Score: 0.2841\n",
            "Top 1: F1 Score = 0.3950, Model = densenet121_2\n",
            "Top 2: F1 Score = 0.3850, Model = densenet121_1\n",
            "Top 3: F1 Score = 0.3444, Model = densenet121_3\n",
            "Top 4: F1 Score = 0.2841, Model = densenet121_4\n",
            "Top 5: F1 Score = 0.2841, Model = densenet121_5\n",
            "Epoch 7/30 - Training Loss: 1.4108 - Accuracy: 0.6842 - F1 Score: 0.6527\n",
            "Validation Accuracy: 0.4727 - F1 Score: 0.3229\n",
            "Top 1: F1 Score = 0.3950, Model = densenet121_2\n",
            "Top 2: F1 Score = 0.3850, Model = densenet121_1\n",
            "Top 3: F1 Score = 0.3444, Model = densenet121_3\n",
            "Top 4: F1 Score = 0.3229, Model = densenet121_7\n",
            "Top 5: F1 Score = 0.2841, Model = densenet121_4\n",
            "Epoch 8/30 - Training Loss: 1.3435 - Accuracy: 0.8092 - F1 Score: 0.8031\n",
            "Validation Accuracy: 0.4818 - F1 Score: 0.3545\n",
            "Top 1: F1 Score = 0.3950, Model = densenet121_2\n",
            "Top 2: F1 Score = 0.3850, Model = densenet121_1\n",
            "Top 3: F1 Score = 0.3545, Model = densenet121_8\n",
            "Top 4: F1 Score = 0.3444, Model = densenet121_3\n",
            "Top 5: F1 Score = 0.3229, Model = densenet121_7\n",
            "Epoch 9/30 - Training Loss: 1.2634 - Accuracy: 0.9013 - F1 Score: 0.9006\n",
            "Validation Accuracy: 0.4818 - F1 Score: 0.4068\n",
            "Top 1: F1 Score = 0.4068, Model = densenet121_9\n",
            "Top 2: F1 Score = 0.3950, Model = densenet121_2\n",
            "Top 3: F1 Score = 0.3850, Model = densenet121_1\n",
            "Top 4: F1 Score = 0.3545, Model = densenet121_8\n",
            "Top 5: F1 Score = 0.3444, Model = densenet121_3\n",
            "Epoch 10/30 - Training Loss: 1.1441 - Accuracy: 0.9408 - F1 Score: 0.9407\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.4495\n",
            "Top 1: F1 Score = 0.4495, Model = densenet121_10\n",
            "Top 2: F1 Score = 0.4068, Model = densenet121_9\n",
            "Top 3: F1 Score = 0.3950, Model = densenet121_2\n",
            "Top 4: F1 Score = 0.3850, Model = densenet121_1\n",
            "Top 5: F1 Score = 0.3545, Model = densenet121_8\n",
            "Epoch 11/30 - Training Loss: 0.9895 - Accuracy: 0.9803 - F1 Score: 0.9803\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.4828\n",
            "Top 1: F1 Score = 0.4828, Model = densenet121_11\n",
            "Top 2: F1 Score = 0.4495, Model = densenet121_10\n",
            "Top 3: F1 Score = 0.4068, Model = densenet121_9\n",
            "Top 4: F1 Score = 0.3950, Model = densenet121_2\n",
            "Top 5: F1 Score = 0.3850, Model = densenet121_1\n",
            "Epoch 12/30 - Training Loss: 0.9604 - Accuracy: 0.9803 - F1 Score: 0.9803\n",
            "Validation Accuracy: 0.5182 - F1 Score: 0.4814\n",
            "Top 1: F1 Score = 0.4828, Model = densenet121_11\n",
            "Top 2: F1 Score = 0.4814, Model = densenet121_12\n",
            "Top 3: F1 Score = 0.4495, Model = densenet121_10\n",
            "Top 4: F1 Score = 0.4068, Model = densenet121_9\n",
            "Top 5: F1 Score = 0.3950, Model = densenet121_2\n",
            "Epoch 13/30 - Training Loss: 0.8764 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5364 - F1 Score: 0.5105\n",
            "Top 1: F1 Score = 0.5105, Model = densenet121_13\n",
            "Top 2: F1 Score = 0.4828, Model = densenet121_11\n",
            "Top 3: F1 Score = 0.4814, Model = densenet121_12\n",
            "Top 4: F1 Score = 0.4495, Model = densenet121_10\n",
            "Top 5: F1 Score = 0.4068, Model = densenet121_9\n",
            "Epoch 14/30 - Training Loss: 0.7819 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5545 - F1 Score: 0.5336\n",
            "Top 1: F1 Score = 0.5336, Model = densenet121_14\n",
            "Top 2: F1 Score = 0.5105, Model = densenet121_13\n",
            "Top 3: F1 Score = 0.4828, Model = densenet121_11\n",
            "Top 4: F1 Score = 0.4814, Model = densenet121_12\n",
            "Top 5: F1 Score = 0.4495, Model = densenet121_10\n",
            "Epoch 15/30 - Training Loss: 0.7834 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5545 - F1 Score: 0.5372\n",
            "Top 1: F1 Score = 0.5372, Model = densenet121_15\n",
            "Top 2: F1 Score = 0.5336, Model = densenet121_14\n",
            "Top 3: F1 Score = 0.5105, Model = densenet121_13\n",
            "Top 4: F1 Score = 0.4828, Model = densenet121_11\n",
            "Top 5: F1 Score = 0.4814, Model = densenet121_12\n",
            "Epoch 16/30 - Training Loss: 0.6304 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5545 - F1 Score: 0.5372\n",
            "Top 1: F1 Score = 0.5372, Model = densenet121_15\n",
            "Top 2: F1 Score = 0.5372, Model = densenet121_16\n",
            "Top 3: F1 Score = 0.5336, Model = densenet121_14\n",
            "Top 4: F1 Score = 0.5105, Model = densenet121_13\n",
            "Top 5: F1 Score = 0.4828, Model = densenet121_11\n",
            "Epoch 17/30 - Training Loss: 0.5878 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5364 - F1 Score: 0.5217\n",
            "Top 1: F1 Score = 0.5372, Model = densenet121_15\n",
            "Top 2: F1 Score = 0.5372, Model = densenet121_16\n",
            "Top 3: F1 Score = 0.5336, Model = densenet121_14\n",
            "Top 4: F1 Score = 0.5217, Model = densenet121_17\n",
            "Top 5: F1 Score = 0.5105, Model = densenet121_13\n",
            "Epoch 18/30 - Training Loss: 0.5395 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5364 - F1 Score: 0.5274\n",
            "Top 1: F1 Score = 0.5372, Model = densenet121_15\n",
            "Top 2: F1 Score = 0.5372, Model = densenet121_16\n",
            "Top 3: F1 Score = 0.5336, Model = densenet121_14\n",
            "Top 4: F1 Score = 0.5274, Model = densenet121_18\n",
            "Top 5: F1 Score = 0.5217, Model = densenet121_17\n",
            "Epoch 19/30 - Training Loss: 0.5182 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5182 - F1 Score: 0.5152\n",
            "Top 1: F1 Score = 0.5372, Model = densenet121_15\n",
            "Top 2: F1 Score = 0.5372, Model = densenet121_16\n",
            "Top 3: F1 Score = 0.5336, Model = densenet121_14\n",
            "Top 4: F1 Score = 0.5274, Model = densenet121_18\n",
            "Top 5: F1 Score = 0.5217, Model = densenet121_17\n",
            "Epoch 20/30 - Training Loss: 0.4226 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5000 - F1 Score: 0.4984\n",
            "Top 1: F1 Score = 0.5372, Model = densenet121_15\n",
            "Top 2: F1 Score = 0.5372, Model = densenet121_16\n",
            "Top 3: F1 Score = 0.5336, Model = densenet121_14\n",
            "Top 4: F1 Score = 0.5274, Model = densenet121_18\n",
            "Top 5: F1 Score = 0.5217, Model = densenet121_17\n",
            "Epoch 21/30 - Training Loss: 0.3763 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5182 - F1 Score: 0.5190\n",
            "Top 1: F1 Score = 0.5372, Model = densenet121_15\n",
            "Top 2: F1 Score = 0.5372, Model = densenet121_16\n",
            "Top 3: F1 Score = 0.5336, Model = densenet121_14\n",
            "Top 4: F1 Score = 0.5274, Model = densenet121_18\n",
            "Top 5: F1 Score = 0.5217, Model = densenet121_17\n",
            "Epoch 22/30 - Training Loss: 0.3899 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5282\n",
            "Top 1: F1 Score = 0.5372, Model = densenet121_15\n",
            "Top 2: F1 Score = 0.5372, Model = densenet121_16\n",
            "Top 3: F1 Score = 0.5336, Model = densenet121_14\n",
            "Top 4: F1 Score = 0.5282, Model = densenet121_22\n",
            "Top 5: F1 Score = 0.5274, Model = densenet121_18\n",
            "Epoch 23/30 - Training Loss: 0.4074 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5182 - F1 Score: 0.5190\n",
            "Top 1: F1 Score = 0.5372, Model = densenet121_15\n",
            "Top 2: F1 Score = 0.5372, Model = densenet121_16\n",
            "Top 3: F1 Score = 0.5336, Model = densenet121_14\n",
            "Top 4: F1 Score = 0.5282, Model = densenet121_22\n",
            "Top 5: F1 Score = 0.5274, Model = densenet121_18\n",
            "Epoch 24/30 - Training Loss: 0.4384 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5263\n",
            "Top 1: F1 Score = 0.5372, Model = densenet121_15\n",
            "Top 2: F1 Score = 0.5372, Model = densenet121_16\n",
            "Top 3: F1 Score = 0.5336, Model = densenet121_14\n",
            "Top 4: F1 Score = 0.5282, Model = densenet121_22\n",
            "Top 5: F1 Score = 0.5274, Model = densenet121_18\n",
            "Epoch 25/30 - Training Loss: 0.2700 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.5097\n",
            "Top 1: F1 Score = 0.5372, Model = densenet121_15\n",
            "Top 2: F1 Score = 0.5372, Model = densenet121_16\n",
            "Top 3: F1 Score = 0.5336, Model = densenet121_14\n",
            "Top 4: F1 Score = 0.5282, Model = densenet121_22\n",
            "Top 5: F1 Score = 0.5274, Model = densenet121_18\n",
            "Epoch 26/30 - Training Loss: 0.2600 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5279\n",
            "Top 1: F1 Score = 0.5372, Model = densenet121_15\n",
            "Top 2: F1 Score = 0.5372, Model = densenet121_16\n",
            "Top 3: F1 Score = 0.5336, Model = densenet121_14\n",
            "Top 4: F1 Score = 0.5282, Model = densenet121_22\n",
            "Top 5: F1 Score = 0.5279, Model = densenet121_26\n",
            "Epoch 27/30 - Training Loss: 0.3055 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.5097\n",
            "Top 1: F1 Score = 0.5372, Model = densenet121_15\n",
            "Top 2: F1 Score = 0.5372, Model = densenet121_16\n",
            "Top 3: F1 Score = 0.5336, Model = densenet121_14\n",
            "Top 4: F1 Score = 0.5282, Model = densenet121_22\n",
            "Top 5: F1 Score = 0.5279, Model = densenet121_26\n",
            "Epoch 28/30 - Training Loss: 0.2093 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5282\n",
            "Top 1: F1 Score = 0.5372, Model = densenet121_15\n",
            "Top 2: F1 Score = 0.5372, Model = densenet121_16\n",
            "Top 3: F1 Score = 0.5336, Model = densenet121_14\n",
            "Top 4: F1 Score = 0.5282, Model = densenet121_22\n",
            "Top 5: F1 Score = 0.5282, Model = densenet121_28\n",
            "Epoch 29/30 - Training Loss: 0.2204 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5182 - F1 Score: 0.5192\n",
            "Top 1: F1 Score = 0.5372, Model = densenet121_15\n",
            "Top 2: F1 Score = 0.5372, Model = densenet121_16\n",
            "Top 3: F1 Score = 0.5336, Model = densenet121_14\n",
            "Top 4: F1 Score = 0.5282, Model = densenet121_22\n",
            "Top 5: F1 Score = 0.5282, Model = densenet121_28\n",
            "Epoch 30/30 - Training Loss: 0.2091 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5182 - F1 Score: 0.5192\n",
            "Top 1: F1 Score = 0.5372, Model = densenet121_15\n",
            "Top 2: F1 Score = 0.5372, Model = densenet121_16\n",
            "Top 3: F1 Score = 0.5336, Model = densenet121_14\n",
            "Top 4: F1 Score = 0.5282, Model = densenet121_22\n",
            "Top 5: F1 Score = 0.5282, Model = densenet121_28\n",
            "Top 5 models saved:\n",
            "F1 Score: 0.5372 - Model: densenet121_15\n",
            "F1 Score: 0.5372 - Model: densenet121_16\n",
            "F1 Score: 0.5336 - Model: densenet121_14\n",
            "F1 Score: 0.5282 - Model: densenet121_22\n",
            "F1 Score: 0.5282 - Model: densenet121_28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Models for Image Differencing\n",
        "for model_name, model in models_dict.items():\n",
        "  print(f\"Training {model_name}...\")\n",
        "  if model_name == 'resnet18':\n",
        "    model = modify_resnet_for_grayscale(model)\n",
        "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "  elif model_name == 'vgg11':\n",
        "    model = modify_vgg_for_grayscale(model)\n",
        "    model.classifier[6] = nn.Linear(model.classifier[6].in_features, 2)\n",
        "  elif model_name == 'densenet121':\n",
        "    model = modify_vgg_for_grayscale(model)\n",
        "    model.classifier = nn.Linear(model.classifier.in_features, 2)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(device)\n",
        "  model = model.to(device)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
        "  num_epochs = 30\n",
        "  metrics_df = train_model(model,\n",
        "                           model_name,\n",
        "                          diff_trainloader,\n",
        "                          diff_testloader,\n",
        "                          num_epochs,\n",
        "                          criterion,\n",
        "                          optimizer,\n",
        "                          device,\n",
        "                          metrics_df,\n",
        "                          \"/content/drive/MyDrive/PBHLT7120_Project/ProjectMaterials/Models/ImageDiffing/\",\n",
        "                          \"/content/drive/MyDrive/PBHLT7120_Project/ProjectMaterials/Models/ImageDiffing/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOHK2JAAkqF4",
        "outputId": "3b9e8338-ccea-410d-89da-5bf11797ea41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training resnet18...\n",
            "cuda\n",
            "Epoch 1/30 - Training Loss: 2.5502 - Accuracy: 0.4934 - F1 Score: 0.3391\n",
            "Validation Accuracy: 0.5455 - F1 Score: 0.3850\n",
            "Top 1: F1 Score = 0.3850, Model = resnet18_1\n",
            "Epoch 2/30 - Training Loss: 2.1349 - Accuracy: 0.5197 - F1 Score: 0.3626\n",
            "Validation Accuracy: 0.5455 - F1 Score: 0.3850\n",
            "Top 1: F1 Score = 0.3850, Model = resnet18_1\n",
            "Top 2: F1 Score = 0.3850, Model = resnet18_2\n",
            "Epoch 3/30 - Training Loss: 1.8892 - Accuracy: 0.5329 - F1 Score: 0.3906\n",
            "Validation Accuracy: 0.5455 - F1 Score: 0.4006\n",
            "Top 1: F1 Score = 0.4006, Model = resnet18_3\n",
            "Top 2: F1 Score = 0.3850, Model = resnet18_1\n",
            "Top 3: F1 Score = 0.3850, Model = resnet18_2\n",
            "Epoch 4/30 - Training Loss: 1.6953 - Accuracy: 0.5592 - F1 Score: 0.4431\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.3914\n",
            "Top 1: F1 Score = 0.4006, Model = resnet18_3\n",
            "Top 2: F1 Score = 0.3914, Model = resnet18_4\n",
            "Top 3: F1 Score = 0.3850, Model = resnet18_1\n",
            "Top 4: F1 Score = 0.3850, Model = resnet18_2\n",
            "Epoch 5/30 - Training Loss: 1.4970 - Accuracy: 0.6645 - F1 Score: 0.6176\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.4489\n",
            "Top 1: F1 Score = 0.4489, Model = resnet18_5\n",
            "Top 2: F1 Score = 0.4006, Model = resnet18_3\n",
            "Top 3: F1 Score = 0.3914, Model = resnet18_4\n",
            "Top 4: F1 Score = 0.3850, Model = resnet18_1\n",
            "Top 5: F1 Score = 0.3850, Model = resnet18_2\n",
            "Epoch 6/30 - Training Loss: 1.2987 - Accuracy: 0.7500 - F1 Score: 0.7313\n",
            "Validation Accuracy: 0.5727 - F1 Score: 0.5206\n",
            "Top 1: F1 Score = 0.5206, Model = resnet18_6\n",
            "Top 2: F1 Score = 0.4489, Model = resnet18_5\n",
            "Top 3: F1 Score = 0.4006, Model = resnet18_3\n",
            "Top 4: F1 Score = 0.3914, Model = resnet18_4\n",
            "Top 5: F1 Score = 0.3850, Model = resnet18_1\n",
            "Epoch 7/30 - Training Loss: 1.2084 - Accuracy: 0.8684 - F1 Score: 0.8656\n",
            "Validation Accuracy: 0.6000 - F1 Score: 0.5480\n",
            "Top 1: F1 Score = 0.5480, Model = resnet18_7\n",
            "Top 2: F1 Score = 0.5206, Model = resnet18_6\n",
            "Top 3: F1 Score = 0.4489, Model = resnet18_5\n",
            "Top 4: F1 Score = 0.4006, Model = resnet18_3\n",
            "Top 5: F1 Score = 0.3914, Model = resnet18_4\n",
            "Epoch 8/30 - Training Loss: 1.1125 - Accuracy: 0.9079 - F1 Score: 0.9069\n",
            "Validation Accuracy: 0.5909 - F1 Score: 0.5472\n",
            "Top 1: F1 Score = 0.5480, Model = resnet18_7\n",
            "Top 2: F1 Score = 0.5472, Model = resnet18_8\n",
            "Top 3: F1 Score = 0.5206, Model = resnet18_6\n",
            "Top 4: F1 Score = 0.4489, Model = resnet18_5\n",
            "Top 5: F1 Score = 0.4006, Model = resnet18_3\n",
            "Epoch 9/30 - Training Loss: 0.9060 - Accuracy: 0.9868 - F1 Score: 0.9868\n",
            "Validation Accuracy: 0.6182 - F1 Score: 0.5685\n",
            "Top 1: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 2: F1 Score = 0.5480, Model = resnet18_7\n",
            "Top 3: F1 Score = 0.5472, Model = resnet18_8\n",
            "Top 4: F1 Score = 0.5206, Model = resnet18_6\n",
            "Top 5: F1 Score = 0.4489, Model = resnet18_5\n",
            "Epoch 10/30 - Training Loss: 0.7853 - Accuracy: 0.9934 - F1 Score: 0.9934\n",
            "Validation Accuracy: 0.6182 - F1 Score: 0.5685\n",
            "Top 1: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 2: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 3: F1 Score = 0.5480, Model = resnet18_7\n",
            "Top 4: F1 Score = 0.5472, Model = resnet18_8\n",
            "Top 5: F1 Score = 0.5206, Model = resnet18_6\n",
            "Epoch 11/30 - Training Loss: 0.7163 - Accuracy: 0.9934 - F1 Score: 0.9934\n",
            "Validation Accuracy: 0.5909 - F1 Score: 0.5472\n",
            "Top 1: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 2: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 3: F1 Score = 0.5480, Model = resnet18_7\n",
            "Top 4: F1 Score = 0.5472, Model = resnet18_8\n",
            "Top 5: F1 Score = 0.5472, Model = resnet18_11\n",
            "Epoch 12/30 - Training Loss: 0.7329 - Accuracy: 0.9934 - F1 Score: 0.9934\n",
            "Validation Accuracy: 0.6000 - F1 Score: 0.5543\n",
            "Top 1: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 2: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 3: F1 Score = 0.5543, Model = resnet18_12\n",
            "Top 4: F1 Score = 0.5480, Model = resnet18_7\n",
            "Top 5: F1 Score = 0.5472, Model = resnet18_8\n",
            "Epoch 13/30 - Training Loss: 0.5351 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.6000 - F1 Score: 0.5543\n",
            "Top 1: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 2: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 3: F1 Score = 0.5543, Model = resnet18_12\n",
            "Top 4: F1 Score = 0.5543, Model = resnet18_13\n",
            "Top 5: F1 Score = 0.5480, Model = resnet18_7\n",
            "Epoch 14/30 - Training Loss: 0.4951 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5818 - F1 Score: 0.5340\n",
            "Top 1: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 2: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 3: F1 Score = 0.5543, Model = resnet18_12\n",
            "Top 4: F1 Score = 0.5543, Model = resnet18_13\n",
            "Top 5: F1 Score = 0.5480, Model = resnet18_7\n",
            "Epoch 15/30 - Training Loss: 0.4782 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5818 - F1 Score: 0.5340\n",
            "Top 1: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 2: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 3: F1 Score = 0.5543, Model = resnet18_12\n",
            "Top 4: F1 Score = 0.5543, Model = resnet18_13\n",
            "Top 5: F1 Score = 0.5480, Model = resnet18_7\n",
            "Epoch 16/30 - Training Loss: 0.4617 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5909 - F1 Score: 0.5472\n",
            "Top 1: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 2: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 3: F1 Score = 0.5543, Model = resnet18_12\n",
            "Top 4: F1 Score = 0.5543, Model = resnet18_13\n",
            "Top 5: F1 Score = 0.5480, Model = resnet18_7\n",
            "Epoch 17/30 - Training Loss: 0.3776 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5818 - F1 Score: 0.5340\n",
            "Top 1: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 2: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 3: F1 Score = 0.5543, Model = resnet18_12\n",
            "Top 4: F1 Score = 0.5543, Model = resnet18_13\n",
            "Top 5: F1 Score = 0.5480, Model = resnet18_7\n",
            "Epoch 18/30 - Training Loss: 0.3271 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5818 - F1 Score: 0.5340\n",
            "Top 1: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 2: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 3: F1 Score = 0.5543, Model = resnet18_12\n",
            "Top 4: F1 Score = 0.5543, Model = resnet18_13\n",
            "Top 5: F1 Score = 0.5480, Model = resnet18_7\n",
            "Epoch 19/30 - Training Loss: 0.3228 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5818 - F1 Score: 0.5340\n",
            "Top 1: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 2: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 3: F1 Score = 0.5543, Model = resnet18_12\n",
            "Top 4: F1 Score = 0.5543, Model = resnet18_13\n",
            "Top 5: F1 Score = 0.5480, Model = resnet18_7\n",
            "Epoch 20/30 - Training Loss: 0.3116 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5818 - F1 Score: 0.5340\n",
            "Top 1: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 2: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 3: F1 Score = 0.5543, Model = resnet18_12\n",
            "Top 4: F1 Score = 0.5543, Model = resnet18_13\n",
            "Top 5: F1 Score = 0.5480, Model = resnet18_7\n",
            "Epoch 21/30 - Training Loss: 0.2586 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5727 - F1 Score: 0.5330\n",
            "Top 1: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 2: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 3: F1 Score = 0.5543, Model = resnet18_12\n",
            "Top 4: F1 Score = 0.5543, Model = resnet18_13\n",
            "Top 5: F1 Score = 0.5480, Model = resnet18_7\n",
            "Epoch 22/30 - Training Loss: 0.2628 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5818 - F1 Score: 0.5456\n",
            "Top 1: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 2: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 3: F1 Score = 0.5543, Model = resnet18_12\n",
            "Top 4: F1 Score = 0.5543, Model = resnet18_13\n",
            "Top 5: F1 Score = 0.5480, Model = resnet18_7\n",
            "Epoch 23/30 - Training Loss: 0.2618 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5727 - F1 Score: 0.5330\n",
            "Top 1: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 2: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 3: F1 Score = 0.5543, Model = resnet18_12\n",
            "Top 4: F1 Score = 0.5543, Model = resnet18_13\n",
            "Top 5: F1 Score = 0.5480, Model = resnet18_7\n",
            "Epoch 24/30 - Training Loss: 0.2019 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5727 - F1 Score: 0.5330\n",
            "Top 1: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 2: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 3: F1 Score = 0.5543, Model = resnet18_12\n",
            "Top 4: F1 Score = 0.5543, Model = resnet18_13\n",
            "Top 5: F1 Score = 0.5480, Model = resnet18_7\n",
            "Epoch 25/30 - Training Loss: 0.1772 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5727 - F1 Score: 0.5383\n",
            "Top 1: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 2: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 3: F1 Score = 0.5543, Model = resnet18_12\n",
            "Top 4: F1 Score = 0.5543, Model = resnet18_13\n",
            "Top 5: F1 Score = 0.5480, Model = resnet18_7\n",
            "Epoch 26/30 - Training Loss: 0.1628 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5909 - F1 Score: 0.5670\n",
            "Top 1: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 2: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 3: F1 Score = 0.5670, Model = resnet18_26\n",
            "Top 4: F1 Score = 0.5543, Model = resnet18_12\n",
            "Top 5: F1 Score = 0.5543, Model = resnet18_13\n",
            "Epoch 27/30 - Training Loss: 0.1478 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.6000 - F1 Score: 0.5786\n",
            "Top 1: F1 Score = 0.5786, Model = resnet18_27\n",
            "Top 2: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 3: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 4: F1 Score = 0.5670, Model = resnet18_26\n",
            "Top 5: F1 Score = 0.5543, Model = resnet18_12\n",
            "Epoch 28/30 - Training Loss: 0.1398 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5909 - F1 Score: 0.5709\n",
            "Top 1: F1 Score = 0.5786, Model = resnet18_27\n",
            "Top 2: F1 Score = 0.5709, Model = resnet18_28\n",
            "Top 3: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 4: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 5: F1 Score = 0.5670, Model = resnet18_26\n",
            "Epoch 29/30 - Training Loss: 0.1409 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.6000 - F1 Score: 0.5786\n",
            "Top 1: F1 Score = 0.5786, Model = resnet18_27\n",
            "Top 2: F1 Score = 0.5786, Model = resnet18_29\n",
            "Top 3: F1 Score = 0.5709, Model = resnet18_28\n",
            "Top 4: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 5: F1 Score = 0.5685, Model = resnet18_10\n",
            "Epoch 30/30 - Training Loss: 0.1880 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5909 - F1 Score: 0.5670\n",
            "Top 1: F1 Score = 0.5786, Model = resnet18_27\n",
            "Top 2: F1 Score = 0.5786, Model = resnet18_29\n",
            "Top 3: F1 Score = 0.5709, Model = resnet18_28\n",
            "Top 4: F1 Score = 0.5685, Model = resnet18_9\n",
            "Top 5: F1 Score = 0.5685, Model = resnet18_10\n",
            "Top 5 models saved:\n",
            "F1 Score: 0.5786 - Model: resnet18_27\n",
            "F1 Score: 0.5786 - Model: resnet18_29\n",
            "F1 Score: 0.5709 - Model: resnet18_28\n",
            "F1 Score: 0.5685 - Model: resnet18_9\n",
            "F1 Score: 0.5685 - Model: resnet18_10\n",
            "Training vgg11...\n",
            "cuda\n",
            "Epoch 1/30 - Training Loss: 2.3317 - Accuracy: 0.4276 - F1 Score: 0.4271\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.3950\n",
            "Top 1: F1 Score = 0.3950, Model = vgg11_1\n",
            "Epoch 2/30 - Training Loss: 2.0013 - Accuracy: 0.6053 - F1 Score: 0.5969\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.3950\n",
            "Top 1: F1 Score = 0.3950, Model = vgg11_1\n",
            "Top 2: F1 Score = 0.3950, Model = vgg11_2\n",
            "Epoch 3/30 - Training Loss: 2.0869 - Accuracy: 0.5592 - F1 Score: 0.5374\n",
            "Validation Accuracy: 0.5000 - F1 Score: 0.4655\n",
            "Top 1: F1 Score = 0.4655, Model = vgg11_3\n",
            "Top 2: F1 Score = 0.3950, Model = vgg11_1\n",
            "Top 3: F1 Score = 0.3950, Model = vgg11_2\n",
            "Epoch 4/30 - Training Loss: 1.8379 - Accuracy: 0.6382 - F1 Score: 0.6375\n",
            "Validation Accuracy: 0.4455 - F1 Score: 0.4449\n",
            "Top 1: F1 Score = 0.4655, Model = vgg11_3\n",
            "Top 2: F1 Score = 0.4449, Model = vgg11_4\n",
            "Top 3: F1 Score = 0.3950, Model = vgg11_1\n",
            "Top 4: F1 Score = 0.3950, Model = vgg11_2\n",
            "Epoch 5/30 - Training Loss: 1.8672 - Accuracy: 0.7039 - F1 Score: 0.7034\n",
            "Validation Accuracy: 0.4364 - F1 Score: 0.4364\n",
            "Top 1: F1 Score = 0.4655, Model = vgg11_3\n",
            "Top 2: F1 Score = 0.4449, Model = vgg11_4\n",
            "Top 3: F1 Score = 0.4364, Model = vgg11_5\n",
            "Top 4: F1 Score = 0.3950, Model = vgg11_1\n",
            "Top 5: F1 Score = 0.3950, Model = vgg11_2\n",
            "Epoch 6/30 - Training Loss: 1.7794 - Accuracy: 0.6645 - F1 Score: 0.6638\n",
            "Validation Accuracy: 0.4636 - F1 Score: 0.4619\n",
            "Top 1: F1 Score = 0.4655, Model = vgg11_3\n",
            "Top 2: F1 Score = 0.4619, Model = vgg11_6\n",
            "Top 3: F1 Score = 0.4449, Model = vgg11_4\n",
            "Top 4: F1 Score = 0.4364, Model = vgg11_5\n",
            "Top 5: F1 Score = 0.3950, Model = vgg11_1\n",
            "Epoch 7/30 - Training Loss: 1.5919 - Accuracy: 0.7632 - F1 Score: 0.7630\n",
            "Validation Accuracy: 0.4545 - F1 Score: 0.4535\n",
            "Top 1: F1 Score = 0.4655, Model = vgg11_3\n",
            "Top 2: F1 Score = 0.4619, Model = vgg11_6\n",
            "Top 3: F1 Score = 0.4535, Model = vgg11_7\n",
            "Top 4: F1 Score = 0.4449, Model = vgg11_4\n",
            "Top 5: F1 Score = 0.4364, Model = vgg11_5\n",
            "Epoch 8/30 - Training Loss: 1.6914 - Accuracy: 0.7303 - F1 Score: 0.7297\n",
            "Validation Accuracy: 0.4545 - F1 Score: 0.4545\n",
            "Top 1: F1 Score = 0.4655, Model = vgg11_3\n",
            "Top 2: F1 Score = 0.4619, Model = vgg11_6\n",
            "Top 3: F1 Score = 0.4545, Model = vgg11_8\n",
            "Top 4: F1 Score = 0.4535, Model = vgg11_7\n",
            "Top 5: F1 Score = 0.4449, Model = vgg11_4\n",
            "Epoch 9/30 - Training Loss: 1.4934 - Accuracy: 0.8158 - F1 Score: 0.8157\n",
            "Validation Accuracy: 0.4455 - F1 Score: 0.4464\n",
            "Top 1: F1 Score = 0.4655, Model = vgg11_3\n",
            "Top 2: F1 Score = 0.4619, Model = vgg11_6\n",
            "Top 3: F1 Score = 0.4545, Model = vgg11_8\n",
            "Top 4: F1 Score = 0.4535, Model = vgg11_7\n",
            "Top 5: F1 Score = 0.4464, Model = vgg11_9\n",
            "Epoch 10/30 - Training Loss: 1.4450 - Accuracy: 0.8092 - F1 Score: 0.8092\n",
            "Validation Accuracy: 0.4636 - F1 Score: 0.4646\n",
            "Top 1: F1 Score = 0.4655, Model = vgg11_3\n",
            "Top 2: F1 Score = 0.4646, Model = vgg11_10\n",
            "Top 3: F1 Score = 0.4619, Model = vgg11_6\n",
            "Top 4: F1 Score = 0.4545, Model = vgg11_8\n",
            "Top 5: F1 Score = 0.4535, Model = vgg11_7\n",
            "Epoch 11/30 - Training Loss: 1.3732 - Accuracy: 0.8026 - F1 Score: 0.8024\n",
            "Validation Accuracy: 0.4727 - F1 Score: 0.4727\n",
            "Top 1: F1 Score = 0.4727, Model = vgg11_11\n",
            "Top 2: F1 Score = 0.4655, Model = vgg11_3\n",
            "Top 3: F1 Score = 0.4646, Model = vgg11_10\n",
            "Top 4: F1 Score = 0.4619, Model = vgg11_6\n",
            "Top 5: F1 Score = 0.4545, Model = vgg11_8\n",
            "Epoch 12/30 - Training Loss: 1.1046 - Accuracy: 0.8618 - F1 Score: 0.8618\n",
            "Validation Accuracy: 0.4636 - F1 Score: 0.4631\n",
            "Top 1: F1 Score = 0.4727, Model = vgg11_11\n",
            "Top 2: F1 Score = 0.4655, Model = vgg11_3\n",
            "Top 3: F1 Score = 0.4646, Model = vgg11_10\n",
            "Top 4: F1 Score = 0.4631, Model = vgg11_12\n",
            "Top 5: F1 Score = 0.4619, Model = vgg11_6\n",
            "Epoch 13/30 - Training Loss: 1.1187 - Accuracy: 0.8618 - F1 Score: 0.8619\n",
            "Validation Accuracy: 0.4909 - F1 Score: 0.4909\n",
            "Top 1: F1 Score = 0.4909, Model = vgg11_13\n",
            "Top 2: F1 Score = 0.4727, Model = vgg11_11\n",
            "Top 3: F1 Score = 0.4655, Model = vgg11_3\n",
            "Top 4: F1 Score = 0.4646, Model = vgg11_10\n",
            "Top 5: F1 Score = 0.4631, Model = vgg11_12\n",
            "Epoch 14/30 - Training Loss: 1.0359 - Accuracy: 0.8684 - F1 Score: 0.8684\n",
            "Validation Accuracy: 0.4727 - F1 Score: 0.4738\n",
            "Top 1: F1 Score = 0.4909, Model = vgg11_13\n",
            "Top 2: F1 Score = 0.4738, Model = vgg11_14\n",
            "Top 3: F1 Score = 0.4727, Model = vgg11_11\n",
            "Top 4: F1 Score = 0.4655, Model = vgg11_3\n",
            "Top 5: F1 Score = 0.4646, Model = vgg11_10\n",
            "Epoch 15/30 - Training Loss: 0.9517 - Accuracy: 0.8750 - F1 Score: 0.8749\n",
            "Validation Accuracy: 0.4727 - F1 Score: 0.4717\n",
            "Top 1: F1 Score = 0.4909, Model = vgg11_13\n",
            "Top 2: F1 Score = 0.4738, Model = vgg11_14\n",
            "Top 3: F1 Score = 0.4727, Model = vgg11_11\n",
            "Top 4: F1 Score = 0.4717, Model = vgg11_15\n",
            "Top 5: F1 Score = 0.4655, Model = vgg11_3\n",
            "Epoch 16/30 - Training Loss: 0.7778 - Accuracy: 0.9079 - F1 Score: 0.9078\n",
            "Validation Accuracy: 0.4909 - F1 Score: 0.4916\n",
            "Top 1: F1 Score = 0.4916, Model = vgg11_16\n",
            "Top 2: F1 Score = 0.4909, Model = vgg11_13\n",
            "Top 3: F1 Score = 0.4738, Model = vgg11_14\n",
            "Top 4: F1 Score = 0.4727, Model = vgg11_11\n",
            "Top 5: F1 Score = 0.4717, Model = vgg11_15\n",
            "Epoch 17/30 - Training Loss: 0.7012 - Accuracy: 0.9211 - F1 Score: 0.9210\n",
            "Validation Accuracy: 0.4909 - F1 Score: 0.4909\n",
            "Top 1: F1 Score = 0.4916, Model = vgg11_16\n",
            "Top 2: F1 Score = 0.4909, Model = vgg11_13\n",
            "Top 3: F1 Score = 0.4909, Model = vgg11_17\n",
            "Top 4: F1 Score = 0.4738, Model = vgg11_14\n",
            "Top 5: F1 Score = 0.4727, Model = vgg11_11\n",
            "Epoch 18/30 - Training Loss: 0.6907 - Accuracy: 0.9474 - F1 Score: 0.9473\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.5091\n",
            "Top 1: F1 Score = 0.5091, Model = vgg11_18\n",
            "Top 2: F1 Score = 0.4916, Model = vgg11_16\n",
            "Top 3: F1 Score = 0.4909, Model = vgg11_13\n",
            "Top 4: F1 Score = 0.4909, Model = vgg11_17\n",
            "Top 5: F1 Score = 0.4738, Model = vgg11_14\n",
            "Epoch 19/30 - Training Loss: 0.6471 - Accuracy: 0.9211 - F1 Score: 0.9211\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.5097\n",
            "Top 1: F1 Score = 0.5097, Model = vgg11_19\n",
            "Top 2: F1 Score = 0.5091, Model = vgg11_18\n",
            "Top 3: F1 Score = 0.4916, Model = vgg11_16\n",
            "Top 4: F1 Score = 0.4909, Model = vgg11_13\n",
            "Top 5: F1 Score = 0.4909, Model = vgg11_17\n",
            "Epoch 20/30 - Training Loss: 0.6276 - Accuracy: 0.9474 - F1 Score: 0.9474\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.5097\n",
            "Top 1: F1 Score = 0.5097, Model = vgg11_19\n",
            "Top 2: F1 Score = 0.5097, Model = vgg11_20\n",
            "Top 3: F1 Score = 0.5091, Model = vgg11_18\n",
            "Top 4: F1 Score = 0.4916, Model = vgg11_16\n",
            "Top 5: F1 Score = 0.4909, Model = vgg11_13\n",
            "Epoch 21/30 - Training Loss: 0.5356 - Accuracy: 0.9408 - F1 Score: 0.9408\n",
            "Validation Accuracy: 0.4909 - F1 Score: 0.4909\n",
            "Top 1: F1 Score = 0.5097, Model = vgg11_19\n",
            "Top 2: F1 Score = 0.5097, Model = vgg11_20\n",
            "Top 3: F1 Score = 0.5091, Model = vgg11_18\n",
            "Top 4: F1 Score = 0.4916, Model = vgg11_16\n",
            "Top 5: F1 Score = 0.4909, Model = vgg11_13\n",
            "Epoch 22/30 - Training Loss: 0.4108 - Accuracy: 0.9671 - F1 Score: 0.9671\n",
            "Validation Accuracy: 0.4909 - F1 Score: 0.4909\n",
            "Top 1: F1 Score = 0.5097, Model = vgg11_19\n",
            "Top 2: F1 Score = 0.5097, Model = vgg11_20\n",
            "Top 3: F1 Score = 0.5091, Model = vgg11_18\n",
            "Top 4: F1 Score = 0.4916, Model = vgg11_16\n",
            "Top 5: F1 Score = 0.4909, Model = vgg11_13\n",
            "Epoch 23/30 - Training Loss: 0.4475 - Accuracy: 0.9671 - F1 Score: 0.9671\n",
            "Validation Accuracy: 0.4818 - F1 Score: 0.4827\n",
            "Top 1: F1 Score = 0.5097, Model = vgg11_19\n",
            "Top 2: F1 Score = 0.5097, Model = vgg11_20\n",
            "Top 3: F1 Score = 0.5091, Model = vgg11_18\n",
            "Top 4: F1 Score = 0.4916, Model = vgg11_16\n",
            "Top 5: F1 Score = 0.4909, Model = vgg11_13\n",
            "Epoch 24/30 - Training Loss: 0.3118 - Accuracy: 0.9737 - F1 Score: 0.9737\n",
            "Validation Accuracy: 0.4727 - F1 Score: 0.4734\n",
            "Top 1: F1 Score = 0.5097, Model = vgg11_19\n",
            "Top 2: F1 Score = 0.5097, Model = vgg11_20\n",
            "Top 3: F1 Score = 0.5091, Model = vgg11_18\n",
            "Top 4: F1 Score = 0.4916, Model = vgg11_16\n",
            "Top 5: F1 Score = 0.4909, Model = vgg11_13\n",
            "Epoch 25/30 - Training Loss: 0.2696 - Accuracy: 0.9868 - F1 Score: 0.9868\n",
            "Validation Accuracy: 0.4727 - F1 Score: 0.4717\n",
            "Top 1: F1 Score = 0.5097, Model = vgg11_19\n",
            "Top 2: F1 Score = 0.5097, Model = vgg11_20\n",
            "Top 3: F1 Score = 0.5091, Model = vgg11_18\n",
            "Top 4: F1 Score = 0.4916, Model = vgg11_16\n",
            "Top 5: F1 Score = 0.4909, Model = vgg11_13\n",
            "Epoch 26/30 - Training Loss: 0.2351 - Accuracy: 0.9934 - F1 Score: 0.9934\n",
            "Validation Accuracy: 0.4636 - F1 Score: 0.4640\n",
            "Top 1: F1 Score = 0.5097, Model = vgg11_19\n",
            "Top 2: F1 Score = 0.5097, Model = vgg11_20\n",
            "Top 3: F1 Score = 0.5091, Model = vgg11_18\n",
            "Top 4: F1 Score = 0.4916, Model = vgg11_16\n",
            "Top 5: F1 Score = 0.4909, Model = vgg11_13\n",
            "Epoch 27/30 - Training Loss: 0.2178 - Accuracy: 0.9934 - F1 Score: 0.9934\n",
            "Validation Accuracy: 0.4455 - F1 Score: 0.4466\n",
            "Top 1: F1 Score = 0.5097, Model = vgg11_19\n",
            "Top 2: F1 Score = 0.5097, Model = vgg11_20\n",
            "Top 3: F1 Score = 0.5091, Model = vgg11_18\n",
            "Top 4: F1 Score = 0.4916, Model = vgg11_16\n",
            "Top 5: F1 Score = 0.4909, Model = vgg11_13\n",
            "Epoch 28/30 - Training Loss: 0.1584 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.4364 - F1 Score: 0.4364\n",
            "Top 1: F1 Score = 0.5097, Model = vgg11_19\n",
            "Top 2: F1 Score = 0.5097, Model = vgg11_20\n",
            "Top 3: F1 Score = 0.5091, Model = vgg11_18\n",
            "Top 4: F1 Score = 0.4916, Model = vgg11_16\n",
            "Top 5: F1 Score = 0.4909, Model = vgg11_13\n",
            "Epoch 29/30 - Training Loss: 0.1732 - Accuracy: 0.9934 - F1 Score: 0.9934\n",
            "Validation Accuracy: 0.4455 - F1 Score: 0.4459\n",
            "Top 1: F1 Score = 0.5097, Model = vgg11_19\n",
            "Top 2: F1 Score = 0.5097, Model = vgg11_20\n",
            "Top 3: F1 Score = 0.5091, Model = vgg11_18\n",
            "Top 4: F1 Score = 0.4916, Model = vgg11_16\n",
            "Top 5: F1 Score = 0.4909, Model = vgg11_13\n",
            "Epoch 30/30 - Training Loss: 0.1320 - Accuracy: 0.9803 - F1 Score: 0.9803\n",
            "Validation Accuracy: 0.4636 - F1 Score: 0.4631\n",
            "Top 1: F1 Score = 0.5097, Model = vgg11_19\n",
            "Top 2: F1 Score = 0.5097, Model = vgg11_20\n",
            "Top 3: F1 Score = 0.5091, Model = vgg11_18\n",
            "Top 4: F1 Score = 0.4916, Model = vgg11_16\n",
            "Top 5: F1 Score = 0.4909, Model = vgg11_13\n",
            "Top 5 models saved:\n",
            "F1 Score: 0.5097 - Model: vgg11_19\n",
            "F1 Score: 0.5097 - Model: vgg11_20\n",
            "F1 Score: 0.5091 - Model: vgg11_18\n",
            "F1 Score: 0.4916 - Model: vgg11_16\n",
            "F1 Score: 0.4909 - Model: vgg11_13\n",
            "Training densenet121...\n",
            "cuda\n",
            "Epoch 1/30 - Training Loss: 2.2335 - Accuracy: 0.5132 - F1 Score: 0.3481\n",
            "Validation Accuracy: 0.5455 - F1 Score: 0.3850\n",
            "Top 1: F1 Score = 0.3850, Model = densenet121_1\n",
            "Epoch 2/30 - Training Loss: 1.9831 - Accuracy: 0.5197 - F1 Score: 0.3626\n",
            "Validation Accuracy: 0.5455 - F1 Score: 0.3850\n",
            "Top 1: F1 Score = 0.3850, Model = densenet121_1\n",
            "Top 2: F1 Score = 0.3850, Model = densenet121_2\n",
            "Epoch 3/30 - Training Loss: 1.7818 - Accuracy: 0.5658 - F1 Score: 0.4556\n",
            "Validation Accuracy: 0.5455 - F1 Score: 0.3850\n",
            "Top 1: F1 Score = 0.3850, Model = densenet121_1\n",
            "Top 2: F1 Score = 0.3850, Model = densenet121_2\n",
            "Top 3: F1 Score = 0.3850, Model = densenet121_3\n",
            "Epoch 4/30 - Training Loss: 1.6803 - Accuracy: 0.6382 - F1 Score: 0.5783\n",
            "Validation Accuracy: 0.5455 - F1 Score: 0.3850\n",
            "Top 1: F1 Score = 0.3850, Model = densenet121_1\n",
            "Top 2: F1 Score = 0.3850, Model = densenet121_2\n",
            "Top 3: F1 Score = 0.3850, Model = densenet121_3\n",
            "Top 4: F1 Score = 0.3850, Model = densenet121_4\n",
            "Epoch 5/30 - Training Loss: 1.5472 - Accuracy: 0.7829 - F1 Score: 0.7707\n",
            "Validation Accuracy: 0.5455 - F1 Score: 0.3850\n",
            "Top 1: F1 Score = 0.3850, Model = densenet121_1\n",
            "Top 2: F1 Score = 0.3850, Model = densenet121_2\n",
            "Top 3: F1 Score = 0.3850, Model = densenet121_3\n",
            "Top 4: F1 Score = 0.3850, Model = densenet121_4\n",
            "Top 5: F1 Score = 0.3850, Model = densenet121_5\n",
            "Epoch 6/30 - Training Loss: 1.4069 - Accuracy: 0.8421 - F1 Score: 0.8374\n",
            "Validation Accuracy: 0.5455 - F1 Score: 0.3850\n",
            "Top 1: F1 Score = 0.3850, Model = densenet121_1\n",
            "Top 2: F1 Score = 0.3850, Model = densenet121_2\n",
            "Top 3: F1 Score = 0.3850, Model = densenet121_3\n",
            "Top 4: F1 Score = 0.3850, Model = densenet121_4\n",
            "Top 5: F1 Score = 0.3850, Model = densenet121_5\n",
            "Epoch 7/30 - Training Loss: 1.2833 - Accuracy: 0.9013 - F1 Score: 0.9001\n",
            "Validation Accuracy: 0.5455 - F1 Score: 0.3850\n",
            "Top 1: F1 Score = 0.3850, Model = densenet121_1\n",
            "Top 2: F1 Score = 0.3850, Model = densenet121_2\n",
            "Top 3: F1 Score = 0.3850, Model = densenet121_3\n",
            "Top 4: F1 Score = 0.3850, Model = densenet121_4\n",
            "Top 5: F1 Score = 0.3850, Model = densenet121_5\n",
            "Epoch 8/30 - Training Loss: 1.1984 - Accuracy: 0.9342 - F1 Score: 0.9338\n",
            "Validation Accuracy: 0.5455 - F1 Score: 0.3850\n",
            "Top 1: F1 Score = 0.3850, Model = densenet121_1\n",
            "Top 2: F1 Score = 0.3850, Model = densenet121_2\n",
            "Top 3: F1 Score = 0.3850, Model = densenet121_3\n",
            "Top 4: F1 Score = 0.3850, Model = densenet121_4\n",
            "Top 5: F1 Score = 0.3850, Model = densenet121_5\n",
            "Epoch 9/30 - Training Loss: 1.0887 - Accuracy: 0.9342 - F1 Score: 0.9340\n",
            "Validation Accuracy: 0.5364 - F1 Score: 0.4099\n",
            "Top 1: F1 Score = 0.4099, Model = densenet121_9\n",
            "Top 2: F1 Score = 0.3850, Model = densenet121_1\n",
            "Top 3: F1 Score = 0.3850, Model = densenet121_2\n",
            "Top 4: F1 Score = 0.3850, Model = densenet121_3\n",
            "Top 5: F1 Score = 0.3850, Model = densenet121_4\n",
            "Epoch 10/30 - Training Loss: 1.0296 - Accuracy: 0.9803 - F1 Score: 0.9803\n",
            "Validation Accuracy: 0.5182 - F1 Score: 0.4000\n",
            "Top 1: F1 Score = 0.4099, Model = densenet121_9\n",
            "Top 2: F1 Score = 0.4000, Model = densenet121_10\n",
            "Top 3: F1 Score = 0.3850, Model = densenet121_1\n",
            "Top 4: F1 Score = 0.3850, Model = densenet121_2\n",
            "Top 5: F1 Score = 0.3850, Model = densenet121_3\n",
            "Epoch 11/30 - Training Loss: 0.8893 - Accuracy: 0.9934 - F1 Score: 0.9934\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.4288\n",
            "Top 1: F1 Score = 0.4288, Model = densenet121_11\n",
            "Top 2: F1 Score = 0.4099, Model = densenet121_9\n",
            "Top 3: F1 Score = 0.4000, Model = densenet121_10\n",
            "Top 4: F1 Score = 0.3850, Model = densenet121_1\n",
            "Top 5: F1 Score = 0.3850, Model = densenet121_2\n",
            "Epoch 12/30 - Training Loss: 0.7664 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5182 - F1 Score: 0.4429\n",
            "Top 1: F1 Score = 0.4429, Model = densenet121_12\n",
            "Top 2: F1 Score = 0.4288, Model = densenet121_11\n",
            "Top 3: F1 Score = 0.4099, Model = densenet121_9\n",
            "Top 4: F1 Score = 0.4000, Model = densenet121_10\n",
            "Top 5: F1 Score = 0.3850, Model = densenet121_1\n",
            "Epoch 13/30 - Training Loss: 0.7397 - Accuracy: 0.9934 - F1 Score: 0.9934\n",
            "Validation Accuracy: 0.5000 - F1 Score: 0.4390\n",
            "Top 1: F1 Score = 0.4429, Model = densenet121_12\n",
            "Top 2: F1 Score = 0.4390, Model = densenet121_13\n",
            "Top 3: F1 Score = 0.4288, Model = densenet121_11\n",
            "Top 4: F1 Score = 0.4099, Model = densenet121_9\n",
            "Top 5: F1 Score = 0.4000, Model = densenet121_10\n",
            "Epoch 14/30 - Training Loss: 0.6578 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.4909 - F1 Score: 0.4530\n",
            "Top 1: F1 Score = 0.4530, Model = densenet121_14\n",
            "Top 2: F1 Score = 0.4429, Model = densenet121_12\n",
            "Top 3: F1 Score = 0.4390, Model = densenet121_13\n",
            "Top 4: F1 Score = 0.4288, Model = densenet121_11\n",
            "Top 5: F1 Score = 0.4099, Model = densenet121_9\n",
            "Epoch 15/30 - Training Loss: 0.6079 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.4909 - F1 Score: 0.4636\n",
            "Top 1: F1 Score = 0.4636, Model = densenet121_15\n",
            "Top 2: F1 Score = 0.4530, Model = densenet121_14\n",
            "Top 3: F1 Score = 0.4429, Model = densenet121_12\n",
            "Top 4: F1 Score = 0.4390, Model = densenet121_13\n",
            "Top 5: F1 Score = 0.4288, Model = densenet121_11\n",
            "Epoch 16/30 - Training Loss: 0.5156 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.4872\n",
            "Top 1: F1 Score = 0.4872, Model = densenet121_16\n",
            "Top 2: F1 Score = 0.4636, Model = densenet121_15\n",
            "Top 3: F1 Score = 0.4530, Model = densenet121_14\n",
            "Top 4: F1 Score = 0.4429, Model = densenet121_12\n",
            "Top 5: F1 Score = 0.4390, Model = densenet121_13\n",
            "Epoch 17/30 - Training Loss: 0.4589 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.4912\n",
            "Top 1: F1 Score = 0.4912, Model = densenet121_17\n",
            "Top 2: F1 Score = 0.4872, Model = densenet121_16\n",
            "Top 3: F1 Score = 0.4636, Model = densenet121_15\n",
            "Top 4: F1 Score = 0.4530, Model = densenet121_14\n",
            "Top 5: F1 Score = 0.4429, Model = densenet121_12\n",
            "Epoch 18/30 - Training Loss: 0.4085 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.4912\n",
            "Top 1: F1 Score = 0.4912, Model = densenet121_17\n",
            "Top 2: F1 Score = 0.4912, Model = densenet121_18\n",
            "Top 3: F1 Score = 0.4872, Model = densenet121_16\n",
            "Top 4: F1 Score = 0.4636, Model = densenet121_15\n",
            "Top 5: F1 Score = 0.4530, Model = densenet121_14\n",
            "Epoch 19/30 - Training Loss: 0.3595 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5165\n",
            "Top 1: F1 Score = 0.5165, Model = densenet121_19\n",
            "Top 2: F1 Score = 0.4912, Model = densenet121_17\n",
            "Top 3: F1 Score = 0.4912, Model = densenet121_18\n",
            "Top 4: F1 Score = 0.4872, Model = densenet121_16\n",
            "Top 5: F1 Score = 0.4636, Model = densenet121_15\n",
            "Epoch 20/30 - Training Loss: 0.3275 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5165\n",
            "Top 1: F1 Score = 0.5165, Model = densenet121_19\n",
            "Top 2: F1 Score = 0.5165, Model = densenet121_20\n",
            "Top 3: F1 Score = 0.4912, Model = densenet121_17\n",
            "Top 4: F1 Score = 0.4912, Model = densenet121_18\n",
            "Top 5: F1 Score = 0.4872, Model = densenet121_16\n",
            "Epoch 21/30 - Training Loss: 0.2994 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5091 - F1 Score: 0.5007\n",
            "Top 1: F1 Score = 0.5165, Model = densenet121_19\n",
            "Top 2: F1 Score = 0.5165, Model = densenet121_20\n",
            "Top 3: F1 Score = 0.5007, Model = densenet121_21\n",
            "Top 4: F1 Score = 0.4912, Model = densenet121_17\n",
            "Top 5: F1 Score = 0.4912, Model = densenet121_18\n",
            "Epoch 22/30 - Training Loss: 0.2815 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5215\n",
            "Top 1: F1 Score = 0.5215, Model = densenet121_22\n",
            "Top 2: F1 Score = 0.5165, Model = densenet121_19\n",
            "Top 3: F1 Score = 0.5165, Model = densenet121_20\n",
            "Top 4: F1 Score = 0.5007, Model = densenet121_21\n",
            "Top 5: F1 Score = 0.4912, Model = densenet121_17\n",
            "Epoch 23/30 - Training Loss: 0.2776 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5192\n",
            "Top 1: F1 Score = 0.5215, Model = densenet121_22\n",
            "Top 2: F1 Score = 0.5192, Model = densenet121_23\n",
            "Top 3: F1 Score = 0.5165, Model = densenet121_19\n",
            "Top 4: F1 Score = 0.5165, Model = densenet121_20\n",
            "Top 5: F1 Score = 0.5007, Model = densenet121_21\n",
            "Epoch 24/30 - Training Loss: 0.2166 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5215\n",
            "Top 1: F1 Score = 0.5215, Model = densenet121_22\n",
            "Top 2: F1 Score = 0.5215, Model = densenet121_24\n",
            "Top 3: F1 Score = 0.5192, Model = densenet121_23\n",
            "Top 4: F1 Score = 0.5165, Model = densenet121_19\n",
            "Top 5: F1 Score = 0.5165, Model = densenet121_20\n",
            "Epoch 25/30 - Training Loss: 0.2410 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5215\n",
            "Top 1: F1 Score = 0.5215, Model = densenet121_22\n",
            "Top 2: F1 Score = 0.5215, Model = densenet121_24\n",
            "Top 3: F1 Score = 0.5215, Model = densenet121_25\n",
            "Top 4: F1 Score = 0.5192, Model = densenet121_23\n",
            "Top 5: F1 Score = 0.5165, Model = densenet121_19\n",
            "Epoch 26/30 - Training Loss: 0.1783 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5182 - F1 Score: 0.5133\n",
            "Top 1: F1 Score = 0.5215, Model = densenet121_22\n",
            "Top 2: F1 Score = 0.5215, Model = densenet121_24\n",
            "Top 3: F1 Score = 0.5215, Model = densenet121_25\n",
            "Top 4: F1 Score = 0.5192, Model = densenet121_23\n",
            "Top 5: F1 Score = 0.5165, Model = densenet121_19\n",
            "Epoch 27/30 - Training Loss: 0.1639 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5364 - F1 Score: 0.5334\n",
            "Top 1: F1 Score = 0.5334, Model = densenet121_27\n",
            "Top 2: F1 Score = 0.5215, Model = densenet121_22\n",
            "Top 3: F1 Score = 0.5215, Model = densenet121_24\n",
            "Top 4: F1 Score = 0.5215, Model = densenet121_25\n",
            "Top 5: F1 Score = 0.5192, Model = densenet121_23\n",
            "Epoch 28/30 - Training Loss: 0.1516 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5250\n",
            "Top 1: F1 Score = 0.5334, Model = densenet121_27\n",
            "Top 2: F1 Score = 0.5250, Model = densenet121_28\n",
            "Top 3: F1 Score = 0.5215, Model = densenet121_22\n",
            "Top 4: F1 Score = 0.5215, Model = densenet121_24\n",
            "Top 5: F1 Score = 0.5215, Model = densenet121_25\n",
            "Epoch 29/30 - Training Loss: 0.1422 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5250\n",
            "Top 1: F1 Score = 0.5334, Model = densenet121_27\n",
            "Top 2: F1 Score = 0.5250, Model = densenet121_28\n",
            "Top 3: F1 Score = 0.5250, Model = densenet121_29\n",
            "Top 4: F1 Score = 0.5215, Model = densenet121_22\n",
            "Top 5: F1 Score = 0.5215, Model = densenet121_24\n",
            "Epoch 30/30 - Training Loss: 0.1432 - Accuracy: 1.0000 - F1 Score: 1.0000\n",
            "Validation Accuracy: 0.5273 - F1 Score: 0.5234\n",
            "Top 1: F1 Score = 0.5334, Model = densenet121_27\n",
            "Top 2: F1 Score = 0.5250, Model = densenet121_28\n",
            "Top 3: F1 Score = 0.5250, Model = densenet121_29\n",
            "Top 4: F1 Score = 0.5234, Model = densenet121_30\n",
            "Top 5: F1 Score = 0.5215, Model = densenet121_22\n",
            "Top 5 models saved:\n",
            "F1 Score: 0.5334 - Model: densenet121_27\n",
            "F1 Score: 0.5250 - Model: densenet121_28\n",
            "F1 Score: 0.5250 - Model: densenet121_29\n",
            "F1 Score: 0.5234 - Model: densenet121_30\n",
            "F1 Score: 0.5215 - Model: densenet121_22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "2UYtnVA3VTS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Define Dataset Class\n",
        "class LRMRIDataset(Dataset):\n",
        "    def __init__(self, dataframe, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dataframe (pd.DataFrame): DataFrame containing 'PatientID', 'Description', 'ImageID', and 'Group'.\n",
        "            root_dir (str): Root directory of the dataset.\n",
        "            transform (callable, optional): Optional transform to be applied on an image.\n",
        "        \"\"\"\n",
        "        self.dataframe = dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if isinstance(idx, int):\n",
        "            row = self.dataframe.iloc[idx]\n",
        "        else:\n",
        "            row = self.dataframe.loc[idx]\n",
        "        # Construct image path\n",
        "        new_image_path = os.path.join(\n",
        "            self.root_dir,\n",
        "            f\"{row['FolderName']}\",\n",
        "            \"ADNI\",\n",
        "            row['Subject'],\n",
        "            row['Description'].replace(' ', '_').replace(';', '_')\n",
        "        )\n",
        "        if not os.path.exists(new_image_path):\n",
        "          raise FileNotFoundError(f\"Directory not found: {new_image_path}\")\n",
        "        if os.path.isdir(new_image_path):\n",
        "            date_folder = os.listdir(new_image_path)[0]\n",
        "            date_path = os.path.join(new_image_path, date_folder)\n",
        "            if os.path.isdir(date_path):\n",
        "              image_id = os.listdir(date_path)[0]\n",
        "              image_folder = os.path.join(date_path, image_id)\n",
        "              image_name = os.listdir(image_folder)[0]\n",
        "              image_path = os.path.join(image_folder, image_name)\n",
        "\n",
        "        # Load image\n",
        "        try:\n",
        "            image = nib.load(image_path).get_fdata()\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error loading image: {image_path}. Details: {e}\")\n",
        "        # Normalize to 0,1\n",
        "        image = (image - image.min()) / (image.max() - image.min())\n",
        "        # Scale Pixel Values\n",
        "        image = (image * 255).astype(np.uint8)\n",
        "        # Convert to gray scale\n",
        "        if image.ndim == 3:\n",
        "            image = image[:, :, image.shape[2] // 2]\n",
        "\n",
        "        # Convert NumPy array to PIL image and transform\n",
        "        image = Image.fromarray(image)\n",
        "        if self.transform:\n",
        "          image = self.transform(image)\n",
        "\n",
        "        # Get Label\n",
        "        if (row['DIAGNOSIS_GROUP'] == 'MCI_to_AD')|(row['DIAGNOSIS_GROUP'] == 'Normal_to_AD')|(row['DIAGNOSIS_GROUP'] == 'Only_AD'):\n",
        "          label = 1\n",
        "        else:\n",
        "          label = 0\n",
        "        subject_id = row['Subject']\n",
        "\n",
        "        return image, label, subject_id\n",
        "\n",
        "# Define image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize((224, 224)),  # Resize to a standard size (e.g., for a CNN)\n",
        "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
        "    transforms.Normalize([0.5], [0.5])  # Normalize with mean and std\n",
        "])\n"
      ],
      "metadata": {
        "id": "r6Yka6hi5O-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Sort the DataFrame by PTID and Visit\n",
        "# Assuming your dataframe contains columns ['PTID', 'Visit', 'Image Path', 'Label']\n",
        "def preprocess_and_sort(df):\n",
        "    # Sort the dataframe by PTID and Visit (assuming visits are in 'm06', 'm12', etc.)\n",
        "    df = df.sort_values(by=['Subject', 'Visit'])\n",
        "    return df\n",
        "\n",
        "# 2. Image differencing function\n",
        "def image_differencing(image1_path, image2_path):\n",
        "    # Open the two images\n",
        "    img1 = nib.load(image1_path).get_fdata()\n",
        "    img2 = nib.load(image2_path).get_fdata()\n",
        "    # Get middle slcie\n",
        "    img1_mid = img1[img1.shape[0] // 2, :, :]\n",
        "    img2_mid = img2[img2.shape[0] // 2, :, :]\n",
        "    # Normalize to 0,1\n",
        "    img1_mid = (img1_mid - img1_mid.min()) / (img1_mid.max() - img1_mid.min())\n",
        "    img2_mid = (img2_mid - img2_mid.min()) / (img2_mid.max() - img2_mid.min())\n",
        "    # Scale Pixel Values\n",
        "    image1 = (img1_mid * 255).astype(np.uint8)\n",
        "    image2 = (img2_mid * 255).astype(np.uint8)\n",
        "\n",
        "    # Resize to ensure matching shapes (e.g., 256x256)\n",
        "    target_size = (224, 224)  # Example size\n",
        "    img1_resized = Image.fromarray(image1).resize(target_size, Image.BILINEAR)\n",
        "    img2_resized = Image.fromarray(image2).resize(target_size, Image.BILINEAR)\n",
        "\n",
        "    # Perform image differencing (pixel-wise subtraction)\n",
        "    img_diff = np.abs(np.array(img1_resized) - np.array(img2_resized))\n",
        "\n",
        "    # Convert the difference array back to an image (in case you need to save or visualize it)\n",
        "    img_diff = Image.fromarray(img_diff)\n",
        "\n",
        "    return img_diff\n",
        "\n",
        "# 3. Dataset class for differenced images\n",
        "class LRImageDifferenceDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            df (DataFrame): DataFrame containing columns ['Subject', 'Visit', 'FullPath', 'DIAGNOSIS_GROUP']\n",
        "            transform (callable, optional): Optional transform to be applied on an image.\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        self.data = self.create_image_diff_data()\n",
        "\n",
        "    def create_image_diff_data(self):\n",
        "        \"\"\"\n",
        "        Create the image differences for each PTID.\n",
        "        \"\"\"\n",
        "        data = []\n",
        "        ptids = self.df['Subject'].unique()\n",
        "        for ptid in ptids:\n",
        "            ptid_data = self.df[self.df['Subject'] == ptid]\n",
        "            ptid_data = ptid_data.drop_duplicates(subset=['Visit'])\n",
        "            if len(ptid_data) >= 2:\n",
        "              # For m06-bl difference (Baseline vs. 6 months)\n",
        "              m06_bl_img1 = ptid_data[ptid_data['Visit'] == 'sc']['FullPath'].values[0]\n",
        "              m06_bl_img2 = ptid_data[ptid_data['Visit'] == 'm06']['FullPath'].values[0]\n",
        "              m06_bl_diff = image_differencing(m06_bl_img1, m06_bl_img2)\n",
        "\n",
        "              diagnosis_group = ptid_data['DIAGNOSIS_GROUP'].values[0]\n",
        "              if diagnosis_group in ['MCI_to_AD', 'Normal_to_AD', 'Only_AD']:\n",
        "                  label = 1\n",
        "              else:\n",
        "                  label = 0\n",
        "              subject_id = ptid_data['Subject'].values[0]\n",
        "              # Append the differenced images and corresponding labels to the data list\n",
        "              data.append((m06_bl_diff, label, subject_id))\n",
        "            else:\n",
        "              print(f'Not found for {ptid}')\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label, subject_id = self.data[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label, subject_id\n",
        "\n",
        "# 4. DataLoader with transformations\n",
        "diff_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "-qVVT4pZyawi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create different train/test sets for easier inference\n",
        "lr_6mo = lr_traininfo.loc[lr_traininfo['Visit'].isin(['m06'])]\n",
        "lr_sc = lr_traininfo.loc[lr_traininfo['Visit'].isin(['sc'])]\n",
        "lr_6mo_test = lr_testinfo.loc[lr_testinfo['Visit'].isin(['m06'])]\n",
        "lr_sc_test = lr_testinfo.loc[lr_testinfo['Visit'].isin(['sc'])]\n",
        "\n",
        "# Train Set Loaders\n",
        "lr_6motrainset = LRMRIDataset(lr_6mo, root_dir=root_dir, transform=transform)\n",
        "lr_6motrainloader = DataLoader(lr_6motrainset, batch_size=64, shuffle=False)\n",
        "\n",
        "lr_sctrainset = LRMRIDataset(lr_sc, root_dir=root_dir, transform=transform)\n",
        "lr_sctrainloader = DataLoader(lr_sctrainset, batch_size=64, shuffle=False)\n",
        "\n",
        "lr_diftrain = LRImageDifferenceDataset(lr_traininfo, transform=diff_transform)\n",
        "lr_diftrainloader = DataLoader(lr_diftrain, batch_size=64, shuffle=False)\n",
        "\n",
        "# Test Set Loaders\n",
        "lr_6motestset = LRMRIDataset(lr_6mo_test, root_dir=root_dir, transform=transform)\n",
        "lr_6motestloader = DataLoader(lr_6motestset, batch_size=64, shuffle=False)\n",
        "\n",
        "lr_sctestset = LRMRIDataset(lr_sc_test, root_dir=root_dir, transform=transform)\n",
        "lr_sctestloader = DataLoader(lr_sctestset, batch_size=64, shuffle=False)\n",
        "\n",
        "lr_dif_test = LRImageDifferenceDataset(lr_testinfo, transform=diff_transform)\n",
        "lr_dif_testloader = DataLoader(lr_dif_test, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1WxOF3WqgJ0",
        "outputId": "8c0329c9-147f-44e0-c82f-bb389d4b41b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not found for 033_S_0923\n",
            "Not found for 027_S_0118\n",
            "Not found for 137_S_0800\n",
            "Not found for 033_S_1016\n",
            "Not found for 005_S_0610\n",
            "Not found for 036_S_0945\n",
            "Not found for 035_S_0048\n",
            "Not found for 114_S_0166\n",
            "Not found for 099_S_0470\n",
            "Not found for 057_S_0643\n",
            "Not found for 021_S_0984\n",
            "Not found for 014_S_0563\n",
            "Not found for 014_S_0557\n",
            "Not found for 137_S_0668\n",
            "Not found for 005_S_0553\n",
            "Not found for 036_S_0673\n",
            "Not found for 027_S_0403\n",
            "Not found for 005_S_0221\n",
            "Not found for 002_S_1018\n",
            "Not found for 094_S_0711\n",
            "Not found for 021_S_0343\n",
            "Not found for 114_S_0979\n",
            "Not found for 036_S_0759\n",
            "Not found for 114_S_0416\n",
            "Not found for 036_S_0672\n",
            "Not found for 137_S_0631\n",
            "Not found for 014_S_0558\n",
            "Not found for 099_S_0533\n",
            "Not found for 127_S_0260\n",
            "Not found for 027_S_0835\n",
            "Not found for 099_S_0090\n",
            "Not found for 099_S_0352\n",
            "Not found for 007_S_0316\n",
            "Not found for 005_S_0546\n",
            "Not found for 027_S_0074\n",
            "Not found for 002_S_1155\n",
            "Not found for 033_S_1098\n",
            "Not found for 035_S_0555\n",
            "Not found for 027_S_0644\n",
            "Not found for 137_S_0481\n",
            "Not found for 027_S_0404\n",
            "Not found for 126_S_0708\n",
            "Not found for 127_S_0622\n",
            "Not found for 035_S_0341\n",
            "Not found for 021_S_0337\n",
            "Not found for 114_S_0374\n",
            "Not found for 027_S_0120\n",
            "Not found for 126_S_0865\n",
            "Not found for 002_S_1070\n",
            "Not found for 035_S_0156\n",
            "Not found for 005_S_0324\n",
            "Not found for 027_S_0307\n",
            "Not found for 099_S_0551\n",
            "Not found for 137_S_0443\n",
            "Not found for 126_S_0891\n",
            "Not found for 057_S_0474\n",
            "Not found for 027_S_0408\n",
            "Not found for 127_S_0844\n",
            "Not found for 126_S_0784\n",
            "Not found for 014_S_0520\n",
            "Not found for 027_S_0179\n",
            "Not found for 137_S_1041\n",
            "Not found for 057_S_0839\n",
            "Not found for 041_S_0898\n",
            "Not found for 114_S_0601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate predictions\n",
        "def generate_predictions(model, dataloader, device='cuda'):\n",
        "    predictions_list = []\n",
        "    labels_list = []\n",
        "    visits_list = []\n",
        "    subjects_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels, subject_id in dataloader:\n",
        "            outputs = model(inputs)\n",
        "            probs = softmax(outputs, dim=1)[:, 1].cpu().numpy()  # Probability of class 1\n",
        "            predictions_list.extend(probs)\n",
        "            labels_list.extend(labels.numpy())\n",
        "            subjects_list.extend(subject_id)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'Subject': subjects_list,\n",
        "        'Label': labels_list,\n",
        "        'Probability': predictions_list\n",
        "    })"
      ],
      "metadata": {
        "id": "KXt4CKUa1wFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_models_df = pd.read_csv('/content/drive/MyDrive/PBHLT7120_Project/ProjectMaterials/Models/model_metrics.csv')\n",
        "class_models_df.sort_values(by='Test F1', ascending=False, inplace=True)\n",
        "class_models_df.reset_index(drop=True, inplace=True)\n",
        "dif_models_df = pd.read_csv('/content/drive/MyDrive/PBHLT7120_Project/ProjectMaterials/Models/ImageDiffing/model_metrics.csv')\n",
        "dif_models_df.sort_values(by='Test F1', ascending=False, inplace=True)\n",
        "dif_models_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Add F1 Rank as a column (1-based ranking for readability)\n",
        "class_models_df['F1 Rank'] = class_models_df.index + 1\n",
        "dif_models_df['F1 Rank'] = dif_models_df.index + 1\n",
        "\n",
        "\n",
        "\n",
        "all_models = pd.merge(class_models_df, dif_models_df, on='F1 Rank', suffixes=('_class', '_dif'))\n",
        "all_models.drop_duplicates(subset='Test F1_class', inplace=True)\n",
        "all_models.drop_duplicates(subset='Test F1_dif', inplace=True)\n",
        "\n",
        "all_models.reset_index(drop=True, inplace=True)\n",
        "all_models.head(15)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "Wd59GbURCbI8",
        "outputId": "9ad154f3-d45a-4032-accf-05b18b3f032a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Model_class  Epoch_class  Train Accuracy_class  Train F1_class  \\\n",
              "0         vgg11_23           25              0.953947        0.953857   \n",
              "1   densenet121_16           21              1.000000        1.000000   \n",
              "2      resnet18_29           30              1.000000        1.000000   \n",
              "3   densenet121_22           23              1.000000        1.000000   \n",
              "4   densenet121_18           25              1.000000        1.000000   \n",
              "5      resnet18_26           28              1.000000        1.000000   \n",
              "6      resnet18_22           28              1.000000        1.000000   \n",
              "7   densenet121_17           19              1.000000        1.000000   \n",
              "8   densenet121_13           16              1.000000        1.000000   \n",
              "9         vgg11_13           20              0.868421        0.868353   \n",
              "10        vgg11_17           20              0.861842        0.861860   \n",
              "11     resnet18_15           20              1.000000        1.000000   \n",
              "12     resnet18_17           18              1.000000        1.000000   \n",
              "13     resnet18_12           13              1.000000        1.000000   \n",
              "14         vgg11_6           17              0.723684        0.722529   \n",
              "\n",
              "    Test Accuracy_class  Test F1_class  F1 Rank       Model_dif  Epoch_dif  \\\n",
              "0              0.536364       0.537324        1     resnet18_29         29   \n",
              "1              0.554545       0.537234        9     resnet18_28         29   \n",
              "2              0.536364       0.537172       40     resnet18_10         24   \n",
              "3              0.527273       0.528212       72     resnet18_12         27   \n",
              "4              0.536364       0.527423       98      resnet18_7         15   \n",
              "5              0.527273       0.526335      125     resnet18_10         12   \n",
              "6              0.527273       0.525082      137      resnet18_6         13   \n",
              "7              0.536364       0.521722      145        vgg11_23         27   \n",
              "8              0.536364       0.510476      152  densenet121_16         27   \n",
              "9              0.500000       0.500372      189        vgg11_21         29   \n",
              "10             0.500000       0.496894      209  densenet121_14         29   \n",
              "11             0.518182       0.495566      220  densenet121_27         30   \n",
              "12             0.509091       0.495235      230  densenet121_22         24   \n",
              "13             0.527273       0.493800      238        vgg11_20         28   \n",
              "14             0.490909       0.491922      261  densenet121_18         18   \n",
              "\n",
              "    Train Accuracy_dif  Train F1_dif  Test Accuracy_dif  Test F1_dif  \n",
              "0             1.000000      1.000000           0.600000     0.578571  \n",
              "1             1.000000      1.000000           0.590909     0.570889  \n",
              "2             0.993421      0.993420           0.618182     0.568534  \n",
              "3             0.993421      0.993420           0.600000     0.554286  \n",
              "4             0.868421      0.865618           0.600000     0.547988  \n",
              "5             1.000000      1.000000           0.545455     0.546359  \n",
              "6             1.000000      1.000000           0.545455     0.545455  \n",
              "7             0.953947      0.953857           0.536364     0.537324  \n",
              "8             1.000000      1.000000           0.554545     0.537234  \n",
              "9             0.940789      0.940797           0.536364     0.537169  \n",
              "10            1.000000      1.000000           0.554545     0.533637  \n",
              "11            1.000000      1.000000           0.536364     0.533435  \n",
              "12            1.000000      1.000000           0.527273     0.528212  \n",
              "13            0.921053      0.921012           0.527273     0.527898  \n",
              "14            1.000000      1.000000           0.536364     0.527423  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e01d2b02-91d7-460a-9aca-54630a741336\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_class</th>\n",
              "      <th>Epoch_class</th>\n",
              "      <th>Train Accuracy_class</th>\n",
              "      <th>Train F1_class</th>\n",
              "      <th>Test Accuracy_class</th>\n",
              "      <th>Test F1_class</th>\n",
              "      <th>F1 Rank</th>\n",
              "      <th>Model_dif</th>\n",
              "      <th>Epoch_dif</th>\n",
              "      <th>Train Accuracy_dif</th>\n",
              "      <th>Train F1_dif</th>\n",
              "      <th>Test Accuracy_dif</th>\n",
              "      <th>Test F1_dif</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>vgg11_23</td>\n",
              "      <td>25</td>\n",
              "      <td>0.953947</td>\n",
              "      <td>0.953857</td>\n",
              "      <td>0.536364</td>\n",
              "      <td>0.537324</td>\n",
              "      <td>1</td>\n",
              "      <td>resnet18_29</td>\n",
              "      <td>29</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.578571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>densenet121_16</td>\n",
              "      <td>21</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.554545</td>\n",
              "      <td>0.537234</td>\n",
              "      <td>9</td>\n",
              "      <td>resnet18_28</td>\n",
              "      <td>29</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.590909</td>\n",
              "      <td>0.570889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>resnet18_29</td>\n",
              "      <td>30</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.536364</td>\n",
              "      <td>0.537172</td>\n",
              "      <td>40</td>\n",
              "      <td>resnet18_10</td>\n",
              "      <td>24</td>\n",
              "      <td>0.993421</td>\n",
              "      <td>0.993420</td>\n",
              "      <td>0.618182</td>\n",
              "      <td>0.568534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>densenet121_22</td>\n",
              "      <td>23</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.527273</td>\n",
              "      <td>0.528212</td>\n",
              "      <td>72</td>\n",
              "      <td>resnet18_12</td>\n",
              "      <td>27</td>\n",
              "      <td>0.993421</td>\n",
              "      <td>0.993420</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.554286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>densenet121_18</td>\n",
              "      <td>25</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.536364</td>\n",
              "      <td>0.527423</td>\n",
              "      <td>98</td>\n",
              "      <td>resnet18_7</td>\n",
              "      <td>15</td>\n",
              "      <td>0.868421</td>\n",
              "      <td>0.865618</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.547988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>resnet18_26</td>\n",
              "      <td>28</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.527273</td>\n",
              "      <td>0.526335</td>\n",
              "      <td>125</td>\n",
              "      <td>resnet18_10</td>\n",
              "      <td>12</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.546359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>resnet18_22</td>\n",
              "      <td>28</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.527273</td>\n",
              "      <td>0.525082</td>\n",
              "      <td>137</td>\n",
              "      <td>resnet18_6</td>\n",
              "      <td>13</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.545455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>densenet121_17</td>\n",
              "      <td>19</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.536364</td>\n",
              "      <td>0.521722</td>\n",
              "      <td>145</td>\n",
              "      <td>vgg11_23</td>\n",
              "      <td>27</td>\n",
              "      <td>0.953947</td>\n",
              "      <td>0.953857</td>\n",
              "      <td>0.536364</td>\n",
              "      <td>0.537324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>densenet121_13</td>\n",
              "      <td>16</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.536364</td>\n",
              "      <td>0.510476</td>\n",
              "      <td>152</td>\n",
              "      <td>densenet121_16</td>\n",
              "      <td>27</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.554545</td>\n",
              "      <td>0.537234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>vgg11_13</td>\n",
              "      <td>20</td>\n",
              "      <td>0.868421</td>\n",
              "      <td>0.868353</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500372</td>\n",
              "      <td>189</td>\n",
              "      <td>vgg11_21</td>\n",
              "      <td>29</td>\n",
              "      <td>0.940789</td>\n",
              "      <td>0.940797</td>\n",
              "      <td>0.536364</td>\n",
              "      <td>0.537169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>vgg11_17</td>\n",
              "      <td>20</td>\n",
              "      <td>0.861842</td>\n",
              "      <td>0.861860</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.496894</td>\n",
              "      <td>209</td>\n",
              "      <td>densenet121_14</td>\n",
              "      <td>29</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.554545</td>\n",
              "      <td>0.533637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>resnet18_15</td>\n",
              "      <td>20</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.518182</td>\n",
              "      <td>0.495566</td>\n",
              "      <td>220</td>\n",
              "      <td>densenet121_27</td>\n",
              "      <td>30</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.536364</td>\n",
              "      <td>0.533435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>resnet18_17</td>\n",
              "      <td>18</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.509091</td>\n",
              "      <td>0.495235</td>\n",
              "      <td>230</td>\n",
              "      <td>densenet121_22</td>\n",
              "      <td>24</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.527273</td>\n",
              "      <td>0.528212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>resnet18_12</td>\n",
              "      <td>13</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.527273</td>\n",
              "      <td>0.493800</td>\n",
              "      <td>238</td>\n",
              "      <td>vgg11_20</td>\n",
              "      <td>28</td>\n",
              "      <td>0.921053</td>\n",
              "      <td>0.921012</td>\n",
              "      <td>0.527273</td>\n",
              "      <td>0.527898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>vgg11_6</td>\n",
              "      <td>17</td>\n",
              "      <td>0.723684</td>\n",
              "      <td>0.722529</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>0.491922</td>\n",
              "      <td>261</td>\n",
              "      <td>densenet121_18</td>\n",
              "      <td>18</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.536364</td>\n",
              "      <td>0.527423</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e01d2b02-91d7-460a-9aca-54630a741336')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e01d2b02-91d7-460a-9aca-54630a741336 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e01d2b02-91d7-460a-9aca-54630a741336');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-41b10f1b-9749-4017-b279-308a2e5f0737\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-41b10f1b-9749-4017-b279-308a2e5f0737')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-41b10f1b-9749-4017-b279-308a2e5f0737 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "all_models",
              "summary": "{\n  \"name\": \"all_models\",\n  \"rows\": 28,\n  \"fields\": [\n    {\n      \"column\": \"Model_class\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"vgg11_13\",\n          \"resnet18_9\",\n          \"densenet121_13\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epoch_class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 2,\n        \"max\": 30,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          25,\n          19,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train Accuracy_class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17888096258326253,\n        \"min\": 0.4868421052631579,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.506578947368421,\n          0.5131578947368421,\n          0.9539473684210528\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train F1_class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19759936947236537,\n        \"min\": 0.3188169538891476,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.953857355459186,\n          1.0,\n          0.8220212281997179\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test Accuracy_class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.026176459822585107,\n        \"min\": 0.4636363636363636,\n        \"max\": 0.5545454545454546,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.509090909090909,\n          0.5363636363636364,\n          0.4636363636363636\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test F1_class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04935104797340478,\n        \"min\": 0.3228776123835332,\n        \"max\": 0.5373235460191982,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          0.5003719315645921,\n          0.4128773854801252,\n          0.510475715210255\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Rank\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 118,\n        \"min\": 1,\n        \"max\": 413,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          189,\n          366,\n          152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model_dif\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"vgg11_21\",\n          \"resnet18_22\",\n          \"resnet18_29\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epoch_dif\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 6,\n        \"max\": 30,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          29,\n          24,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train Accuracy_dif\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06196180358534075,\n        \"min\": 0.75,\n        \"max\": 1.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.75,\n          0.993421052631579,\n          0.9210526315789472\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train F1_dif\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06460649662735739,\n        \"min\": 0.731302717900656,\n        \"max\": 1.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9210526315789472,\n          0.9934196273212604,\n          0.921011563067544\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test Accuracy_dif\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03020185128833547,\n        \"min\": 0.509090909090909,\n        \"max\": 0.6181818181818182,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.5727272727272728,\n          0.5909090909090909,\n          0.5545454545454546\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test F1_dif\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.018908239923460263,\n        \"min\": 0.5006993006993007,\n        \"max\": 0.5785714285714286,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          0.5371688934669663,\n          0.5097434967823802,\n          0.5372341653774217\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions for all datasets\n",
        "class_model_root = '/content/drive/MyDrive/PBHLT7120_Project/ProjectMaterials/Models/ClassifiersOne/'\n",
        "dif_model_root = '/content/drive/MyDrive/PBHLT7120_Project/ProjectMaterials/Models/ImageDiffing/'\n",
        "from torchvision.models import resnet18, vgg11, densenet121\n",
        "from torch.nn import functional as F\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "class CustomResNet(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(CustomResNet, self).__init__()\n",
        "        self.model = resnet18(pretrained=False)\n",
        "        modify_resnet_for_grayscale(self.model)\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)  # Custom classification head\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class CustomVGG(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(CustomVGG, self).__init__()\n",
        "        self.model = vgg11(pretrained=False)\n",
        "        modify_vgg_for_grayscale(self.model)\n",
        "        self.model.classifier[6] = nn.Linear(self.model.classifier[6].in_features, num_classes)  # Custom classification head\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "class CustomDenseNet(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(CustomDenseNet, self).__init__()\n",
        "        self.model = densenet121(pretrained=False)\n",
        "        modify_vgg_for_grayscale(self.model)\n",
        "        self.model.classifier = nn.Linear(self.model.classifier.in_features, num_classes)  # Custom classification head\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "for row_id, _ in all_models.iterrows():\n",
        "  torch.cuda.empty_cache()\n",
        "  # Load Models\n",
        "  try:\n",
        "    row = all_models.iloc[row_id]\n",
        "    class_name = row['Model_class']\n",
        "    dif_name = row['Model_dif']\n",
        "    if class_name == 'resnet18%':\n",
        "      class_model = CustomResNet(num_classes=2)\n",
        "    elif class_name == 'vgg11%':\n",
        "      class_model = CustomVGG(num_classes=2)\n",
        "    elif class_name == 'densenet121%':\n",
        "      class_model = CustomDenseNet(num_classes=2)\n",
        "\n",
        "    if dif_name == 'resnet18%':\n",
        "      dif_model = CustomResNet(num_classes=2)\n",
        "    elif dif_name == 'vgg11%':\n",
        "      dif_model = CustomVGG(num_classes=2)\n",
        "    elif dif_name == 'densenet121%':\n",
        "      dif_model = CustomDenseNet(num_classes=2)\n",
        "\n",
        "    class_path = os.path.join(class_model_root, f'{class_name}.pkl')\n",
        "    dif_path = os.path.join(dif_model_root, f'{dif_name}.pkl')\n",
        "    state_dict = torch.load(class_path, map_location=torch.device('cuda'))\n",
        "    state_dict = {f\"model.{k}\": v for k, v in state_dict.items()}\n",
        "    class_model.load_state_dict(state_dict)\n",
        "    state_dict = torch.load(dif_path, map_location=torch.device('cuda'))\n",
        "    state_dict = {f\"model.{k}\": v for k, v in state_dict.items()}\n",
        "    dif_model.load_state_dict(state_dict)\n",
        "\n",
        "    # Create Training Image Predictions\n",
        "    df_6mo_class = generate_predictions(class_model, lr_6motrainloader)\n",
        "    df_sc_class = generate_predictions(class_model, lr_sctrainloader)\n",
        "    df_diff = generate_predictions(dif_model, lr_diftrainloader)\n",
        "\n",
        "    # Create image predictions for test data\n",
        "    df_6mo_class_test = generate_predictions(class_model, lr_6motestloader)\n",
        "    df_sc_class_test = generate_predictions(class_model, lr_sctestloader)\n",
        "    df_diff_test = generate_predictions(dif_model, lr_dif_testloader)\n",
        "\n",
        "    # Combine Training Predictions Into a Single DataFrame\n",
        "    df_6mo_class.rename(columns={'Probability': 'Probability_6mo'}, inplace=True)\n",
        "    df_sc_class.rename(columns={'Probability': 'Probability_sc'}, inplace=True)\n",
        "    df_diff.rename(columns={'Probability': 'Probability_diff'}, inplace=True)\n",
        "    df_diff = df_diff.drop(columns=['Label'])\n",
        "    df_sc_class = df_sc_class.drop(columns=['Label'])\n",
        "    df_combined = pd.merge(df_6mo_class, df_sc_class, on='Subject', how='inner')\n",
        "    df_combined = pd.merge(df_combined, df_diff, on='Subject', how='inner')\n",
        "    df_combined = df_combined.reset_index(drop=True)\n",
        "\n",
        "    # Combine Testing Predictions Into a Single DataFrame\n",
        "    df_6mo_class_test.rename(columns={'Probability': 'Probability_6mo'}, inplace=True)\n",
        "    df_sc_class_test.rename(columns={'Probability': 'Probability_sc'}, inplace=True)\n",
        "    df_diff_test.rename(columns={'Probability': 'Probability_diff'}, inplace=True)\n",
        "    df_6mo_class_test = df_6mo_class_test.reset_index(drop=True)\n",
        "    df_sc_class_test = df_sc_class_test.reset_index(drop=True)\n",
        "    df_diff_test = df_diff_test.reset_index(drop=True)\n",
        "    df_6mo_class_test.drop(columns=['Label'], inplace=True)\n",
        "    df_diff_test.drop(columns=['Label'], inplace=True)\n",
        "    combined_test = pd.merge(df_6mo_class_test, df_sc_class_test, on='Subject', how='inner')\n",
        "    combined_test = pd.merge(combined_test, df_diff_test, on='Subject', how='inner')\n",
        "\n",
        "    # Fit logistic regression and calculate training statistics\n",
        "    lr = LogisticRegression()\n",
        "    lr.fit(df_combined[['Probability_6mo', 'Probability_sc', 'Probability_diff']], df_combined['Label'])\n",
        "    predictions = lr.predict(df_combined[['Probability_6mo', 'Probability_sc', 'Probability_diff']])\n",
        "    accuracy = accuracy_score(df_combined['Label'], predictions)\n",
        "    print(f\"Train Accuracy: {accuracy}\")\n",
        "    f1 = f1_score(df_combined['Label'], predictions)\n",
        "    print(f\"Train F1 Score: {f1}\")\n",
        "\n",
        "    # Evaluate on Test Data\n",
        "    predictions_test = lr.predict(combined_test[['Probability_6mo', 'Probability_sc', 'Probability_diff']])\n",
        "    accuracy_test = accuracy_score(combined_test['Label'], predictions_test)\n",
        "    f1_test = f1_score(combined_test['Label'], predictions_test)\n",
        "    print(f\"Test Accuracy: {accuracy_test}\")\n",
        "    print(f\"Test F1 Score: {f1_test}\")\n",
        "  except:\n",
        "    print('Error')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMfyOwXQ1ylW",
        "outputId": "c9fc9d6e-ffcd-4899-ce58-f05231968e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-f5436a3e68b6>:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(class_path, map_location=torch.device('cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error\n",
            "Error\n",
            "Error\n",
            "Error\n",
            "Error\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-f5436a3e68b6>:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(dif_path, map_location=torch.device('cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.5646551724137931\n",
            "Train F1 Score: 0.34838709677419355\n",
            "Test Accuracy: 0.6504854368932039\n",
            "Test F1 Score: 0.5263157894736842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-f5436a3e68b6>:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(class_path, map_location=torch.device('cuda'))\n",
            "<ipython-input-82-f5436a3e68b6>:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(dif_path, map_location=torch.device('cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.5646551724137931\n",
            "Train F1 Score: 0.36477987421383645\n",
            "Test Accuracy: 0.6504854368932039\n",
            "Test F1 Score: 0.5263157894736842\n",
            "Error\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-f5436a3e68b6>:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(class_path, map_location=torch.device('cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error\n",
            "Error\n",
            "Error\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-f5436a3e68b6>:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(dif_path, map_location=torch.device('cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error\n",
            "Error\n",
            "Error\n",
            "Error\n",
            "Error\n",
            "Error\n",
            "Error\n",
            "Error\n",
            "Error\n",
            "Error\n",
            "Error\n",
            "Error\n",
            "Error\n",
            "Error\n",
            "Error\n",
            "Error\n",
            "Error\n"
          ]
        }
      ]
    }
  ]
}
